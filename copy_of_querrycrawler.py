# -*- coding: utf-8 -*-
"""Copy of QuerryCrawler.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17R0T2ALEQmFqAgFW1M2SYV-oK0KjPo8f
"""

from bs4 import BeautifulSoup as bs
import requests
import nltk
from difflib import SequenceMatcher
import pandas as pd
from urllib.parse import quote
import time

def getTextFromHtml(text):
  return text.replace('<strong>', '').replace('</strong>', '').replace('<cite>', '').replace('</cite>', '').replace('<p>', '').replace('</p>', '')

def similarity(str1, str2):
    return (SequenceMatcher(None,str1,str2).ratio())*100

def querry(searchString):
  start = time.time()
  TIMEOUT_DURATION = 3
  PLAGIARISED_THRESHOLD = 0.8
  url = 'https://www.google.com/search?q='+quote(searchString)
  print(url)
  try:
      content = requests.get(url, headers = {'User-agent': 'your bot 0.1'}, verify=False, timeout=TIMEOUT_DURATION).content
  except:
      return 'null'
  soup = bs(content, 'html.parser')
  # print(soup)
  body = soup.find('body')
  # print(body)
  no_result = body.find_all('li', {"class": "b_no"})
  for r in no_result:
    result_string = r.select('h1')
    if(str(result_string).startswith('[<h1>There are no results for')):
      return 'null'
  results = body.find_all('div', {"class": "b_caption"})
  for result in results:
    cite = result.find('cite')
    content = result.select('p')
    print("link: ", getTextFromHtml(str(cite)))
    print("content: ", getTextFromHtml(str(content).replace('[', '').replace(']', '')))
    highlighted_sentences = getTextFromHtml(str(content).replace('[', '').replace(']', '')).split(".")
    print("bolded sentences: ", highlighted_sentences)
    for sentence in highlighted_sentences:
      sentence = sentence.strip()
      if(sentence=='.' or len(sentence)==0):
        highlighted_sentences.remove(sentence)
    print("post processed bolded sentences: ", highlighted_sentences)
    try:
        website_content = requests.get(getTextFromHtml(str(cite)), timeout=TIMEOUT_DURATION)
    except:
      continue
    while True:
      website_content = website_content.content
      if(website_content!=''):
        break
    website_text = bs(website_content, "lxml").text
    print(website_text)
    matched_sentences = []
    for line in website_text.split('\n'):
      if('googletag.cmd.push' not in line):
        for sentence in line.split('.'):
          for highlighted_sentence in highlighted_sentences:
            if(highlighted_sentence in sentence):
              if len(sentence)!=1:
                matched_sentences.append(sentence)
    print("matched sentence: ", matched_sentences)
    for matched in matched_sentences:
      for searchSentence in searchString.split('.'):
        score = similarity(searchSentence, matched)
        if(score > PLAGIARISED_THRESHOLD):
          return searchSentence
    print('\n')
  end = time.time()
  print("searching time: ", end-start)

searchString = 'HLV Shin Tae-Yong xem Quang Hải là mối nguy hiểm khi Indonesia gặp Việt Nam'

for s in searchString.split('.'):
  print(s.strip())
  if(len(s)==0):
    continue
  print('Plagiarised: ', querry(s.strip())=='null')

def querry(searchString):
  is_plagrism = False
  is_plagrism_links = []
  start = time.time()
  TIMEOUT_DURATION = 3
  PLAGIARISED_THRESHOLD = 0.8
  url = 'https://www.bing.com/search?q='+quote(searchString)
  print(url)
  try:
      content = requests.get(url, headers = {'User-agent': 'your bot 0.1'}, verify=False, timeout=TIMEOUT_DURATION).content
  except:
      return 'null'
  soup = bs(content, 'html.parser')
  # print(soup)
  body = soup.find('body')
  # print(body)
  no_result = body.find_all('li', {"class": "b_no"})
  for r in no_result:
    result_string = r.select('h1')
    if(str(result_string).startswith('[<h1>There are no results for')):
      return 'null'
  results = body.find_all('div', {"class": "b_caption"})
  for result in results:
    cite = result.find('cite')
    # print(result)
    text_para = result.find('p')
    # print(searchString)
    search_unique = set(searchString.lower().split(' '))
    # print(len(search_unique))

    # print(text_para.text)
    result_text = set(text_para.text.split('·')[-1].strip().replace('...','').lower().split(' '))
    # print(len(result_text))
    bold_unique = set(getTextFromHtml(str(result.find_all('strong')).replace('[', '').replace(']', '').replace(',','')).lower().split(' '))
    # print(len(bold_unique))
    
    match_bold = len(search_unique&bold_unique)/len(search_unique)
    result_match = len(result_text&bold_unique)/len(bold_unique)
    print(f'% match bold: {match_bold}')
    print(f'% result match: {result_match}')
    if match_bold > 0.5 and result_match > 0.5:
      is_plagrism = True
      is_plagrism_links.append(cite)
    print("-----"*3)
    # cite = result.find('cite')
    # content = result.select('p')
    # print("link: ", getTextFromHtml(str(cite)))
    # print("content: ", getTextFromHtml(str(content).replace('[', '').replace(']', '')))
    # highlighted_sentences = getTextFromHtml(str(content).replace('[', '').replace(']', '')).split(".")
    # print("bolded sentences: ", highlighted_sentences)
    # for sentence in highlighted_sentences:
    #   sentence = sentence.strip()
    #   if(sentence=='.' or len(sentence)==0):
    #     highlighted_sentences.remove(sentence)
    # print("post processed bolded sentences: ", highlighted_sentences)
    # try:
    #     website_content = requests.get(getTextFromHtml(str(cite)), timeout=TIMEOUT_DURATION)
    # except:
    #   continue
    # while True:
    #   website_content = website_content.content
    #   if(website_content!=''):
    #     break
    # website_text = bs(website_content, "lxml").text
    # print(website_text)
    # matched_sentences = []
  return is_plagrism,is_plagrism_links

is_plag, links = querry('hlv shin tae-yong xem quang hải là mối nguy hiểm khi indonesia gặp việt nam')
if is_plag:
  print('Is Plagiarism')
  print('Links:')
  for i in links:
    print('\t', i.text)
else:
  print('Not Plagiarism')

