{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"T5_Fine_tuning_Phobert.ipynb","provenance":[],"machine_shape":"hm","collapsed_sections":["2RC4vH2aYgZh"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f99502b27dda448aa5223f9333545789":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_68c9bc72cc604d3ebe840054e58973e6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f8842f80304e42e38a06d799c6887bfd","IPY_MODEL_6034683070654958b1c314bc35a0bda3","IPY_MODEL_e6f377b5c7114290809e155918584e4b"]}},"68c9bc72cc604d3ebe840054e58973e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"f8842f80304e42e38a06d799c6887bfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_90be3c64c57f46389a61c6e1b27f8bb6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validation sanity check: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5a46fdfae04242a6ba77795cec8b8d3d"}},"6034683070654958b1c314bc35a0bda3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f27cef51a7f343e0b0149dc1d24bdf9a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8cfebb4301564f84802a2eb426e17e88"}},"e6f377b5c7114290809e155918584e4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0892a83ad4b841838dcd53da3d890f22","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5/5 [00:00&lt;00:00,  8.21it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dc10396467884e328a57fe19242a884f"}},"90be3c64c57f46389a61c6e1b27f8bb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5a46fdfae04242a6ba77795cec8b8d3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f27cef51a7f343e0b0149dc1d24bdf9a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8cfebb4301564f84802a2eb426e17e88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0892a83ad4b841838dcd53da3d890f22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dc10396467884e328a57fe19242a884f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19b895793c6c4683bdfedb1914efc912":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0ceeecbf67874b22b1ceace509e1a2f4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3ea8ac33ee14402da734d7fd2664198d","IPY_MODEL_c184e10fd22b43e4aa6f1743bed4b45d","IPY_MODEL_49673cef5663430e9d86a4e2d4b10a58"]}},"0ceeecbf67874b22b1ceace509e1a2f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"3ea8ac33ee14402da734d7fd2664198d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3a8fac70a7524b41bf161b31644a1b7d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 10: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c6efb0f867742f7b6d6760fa4d02ae2"}},"c184e10fd22b43e4aa6f1743bed4b45d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fe2e49fcb93b417d8a6e1e174054d268","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2418,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2418,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b1d41897674d4c25b5a185c81c80a873"}},"49673cef5663430e9d86a4e2d4b10a58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ceb317454a2648b58ae14d0512bd49b3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2418/2418 [06:37&lt;00:00,  6.08it/s, loss=0.120, v_num=4, val_loss=4.64]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2b75986e64964fdbb776b649cae45b50"}},"3a8fac70a7524b41bf161b31644a1b7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3c6efb0f867742f7b6d6760fa4d02ae2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe2e49fcb93b417d8a6e1e174054d268":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b1d41897674d4c25b5a185c81c80a873":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ceb317454a2648b58ae14d0512bd49b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2b75986e64964fdbb776b649cae45b50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b0fd9a86ddb643bd8df34bf5b5621bbd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3074e1a81dd048fdbd0de1c4993ba1b4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d85f538f84c3459092387296f65456b5","IPY_MODEL_e1d62e6db2e94bd9a09fbddc57ae0698","IPY_MODEL_81fa3c59975e4d03bc5dca872680645d"]}},"3074e1a81dd048fdbd0de1c4993ba1b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"d85f538f84c3459092387296f65456b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_610d06a66bc740b08480023c68a833eb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e0ac750f91304c3299b3a0b5fc154b06"}},"e1d62e6db2e94bd9a09fbddc57ae0698":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e4e68da07f8c42ba91cbc5d714c9f617","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ebddce8de78945838f9b1fd9b21ae438"}},"81fa3c59975e4d03bc5dca872680645d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a4c8df8ded614310b65979e7fad33773","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 519/520 [00:30&lt;00:00, 16.96it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d434d6c4c8f8470bada2a7cd019d5de4"}},"610d06a66bc740b08480023c68a833eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e0ac750f91304c3299b3a0b5fc154b06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e4e68da07f8c42ba91cbc5d714c9f617":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ebddce8de78945838f9b1fd9b21ae438":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4c8df8ded614310b65979e7fad33773":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d434d6c4c8f8470bada2a7cd019d5de4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6882fafe84284c16b978d8503beb598b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f8bc676b7fc94e3c88fbf2928941a398","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7ff938d60fbd429789f1a07299810fca","IPY_MODEL_09cffcafcbe542bda63c85300b33865c","IPY_MODEL_b64b65f806be44fe91445daf5a6ab83b"]}},"f8bc676b7fc94e3c88fbf2928941a398":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"7ff938d60fbd429789f1a07299810fca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e96d7182a4344e78b50759c59fb3b171","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d80dec6f48954d168b2b24f3a363b1b0"}},"09cffcafcbe542bda63c85300b33865c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0392eba8742b430a84b2738c3bd3a344","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0a9476159e3547819260ac04150673b2"}},"b64b65f806be44fe91445daf5a6ab83b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cec859d9d6104a6c85d65ed99da19cc7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 519/520 [00:30&lt;00:00, 16.82it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cbe48690d65145669569a0ffc09dcb5a"}},"e96d7182a4344e78b50759c59fb3b171":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d80dec6f48954d168b2b24f3a363b1b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0392eba8742b430a84b2738c3bd3a344":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0a9476159e3547819260ac04150673b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cec859d9d6104a6c85d65ed99da19cc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cbe48690d65145669569a0ffc09dcb5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1d9829b85134135bac7c92837847036":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_264648e353244bba91dac38f504e8feb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_15c0c26bff874486aa893df78be33362","IPY_MODEL_d02edd4ef4794f7ea763e2da965e2eb8","IPY_MODEL_296832c4984c4191b36a720109a3e2e7"]}},"264648e353244bba91dac38f504e8feb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"15c0c26bff874486aa893df78be33362":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1ebd37079d394527b9157fa740aaa01c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_63d48d9878734231b6fef5a7145fa700"}},"d02edd4ef4794f7ea763e2da965e2eb8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_210af43b19a54ca0b93b7b41b05f5a11","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7f79ada0d1ed4ca780dad49715070cad"}},"296832c4984c4191b36a720109a3e2e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6c6ee033cd2a483b9f5c9f7ae7119a8f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 519/520 [00:31&lt;00:00, 15.44it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_03e1bc97f613498ea0824c8b040d299e"}},"1ebd37079d394527b9157fa740aaa01c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"63d48d9878734231b6fef5a7145fa700":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"210af43b19a54ca0b93b7b41b05f5a11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7f79ada0d1ed4ca780dad49715070cad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c6ee033cd2a483b9f5c9f7ae7119a8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"03e1bc97f613498ea0824c8b040d299e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c62d16743014791ac85e8e87b2814c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_539e3a99aa7f47d7b05a4c4427570da5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_33935782b2a344e8afd9fd9ba898ac1b","IPY_MODEL_b571b9ac4d9a405596f184d704a452fc","IPY_MODEL_fd1bb913e46c4783bcc4700c929af36b"]}},"539e3a99aa7f47d7b05a4c4427570da5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"33935782b2a344e8afd9fd9ba898ac1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_70e3c9d1cfb0471e99eff7828831517d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38b4c9ac743443eca8ddd4dc668cc146"}},"b571b9ac4d9a405596f184d704a452fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b0a3ca9c4a4f42159ce58f8ace137af6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a3dd1cdf16e482db011d82f496246e9"}},"fd1bb913e46c4783bcc4700c929af36b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_89d832a0bc1c449a81ea0961bc465db8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 519/520 [00:31&lt;00:00, 16.79it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8d6bbc44c2dd4d4e9ba12bef8faf58d6"}},"70e3c9d1cfb0471e99eff7828831517d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"38b4c9ac743443eca8ddd4dc668cc146":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b0a3ca9c4a4f42159ce58f8ace137af6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7a3dd1cdf16e482db011d82f496246e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"89d832a0bc1c449a81ea0961bc465db8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8d6bbc44c2dd4d4e9ba12bef8faf58d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e253737e7ce849b389d367539b0523d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d4d8898f045145afa12d74cee9d4867d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2be4d04a3dc942f2b2040da9764c35d4","IPY_MODEL_531f0354d13540d2b8688ad7d48ba0c5","IPY_MODEL_cd585de115b8405aaaf9bb3c0f422311"]}},"d4d8898f045145afa12d74cee9d4867d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2be4d04a3dc942f2b2040da9764c35d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_48a13e3dbda3486b8c1475baf8870145","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cfbe1ce74694446fbd52d79f98fd4f48"}},"531f0354d13540d2b8688ad7d48ba0c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_67be98ee20ce4ab5ae766693b20388bb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":895321,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":895321,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6f29a205110c44dd846ef220aedf5ee7"}},"cd585de115b8405aaaf9bb3c0f422311":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_167b6ef29a474dbbac77709a7beff082","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 874k/874k [00:00&lt;00:00, 4.56MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c76efb6c14074a1492b2df79a37da9df"}},"48a13e3dbda3486b8c1475baf8870145":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cfbe1ce74694446fbd52d79f98fd4f48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67be98ee20ce4ab5ae766693b20388bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6f29a205110c44dd846ef220aedf5ee7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"167b6ef29a474dbbac77709a7beff082":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c76efb6c14074a1492b2df79a37da9df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71a12c93345c4b839d7d7e9408ddf8b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3f76f7ee65754daa8ca80273ded9bcc4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f79800aa5ba44e3f8b4a790dc912aac2","IPY_MODEL_bffbb6963bfb4a49993ea5c73ef0fa68","IPY_MODEL_fb08cb45b7a94fe8912a2492e9606acd"]}},"3f76f7ee65754daa8ca80273ded9bcc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f79800aa5ba44e3f8b4a790dc912aac2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6e5806f9bdc44491bf66b57bee4b792a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_be528583d8b04fcb94e6e524270e709c"}},"bffbb6963bfb4a49993ea5c73ef0fa68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ae55530a9dc44bf1b4f07277247ef0c3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1135173,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1135173,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_64ff58c73395445aae64259786d1ede2"}},"fb08cb45b7a94fe8912a2492e9606acd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f2de31c780944d7fa6d6e131bcd7a076","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.08M/1.08M [00:00&lt;00:00, 1.41MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e30728a25d846109e0c60261adc01e0"}},"6e5806f9bdc44491bf66b57bee4b792a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"be528583d8b04fcb94e6e524270e709c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ae55530a9dc44bf1b4f07277247ef0c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"64ff58c73395445aae64259786d1ede2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2de31c780944d7fa6d6e131bcd7a076":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2e30728a25d846109e0c60261adc01e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8f5582015f8e4380b21d9c11c279cb78":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_60761fe69c8449788a3e649c0a7a3c71","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_91d5edc1ae89469fb413dac19bbc0a14","IPY_MODEL_b84f066e4484423491ccef4a6c966579","IPY_MODEL_f2e15342f93148b3808dc389531bb734"]}},"60761fe69c8449788a3e649c0a7a3c71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91d5edc1ae89469fb413dac19bbc0a14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_70e6c5f263464d4a88572f5a405a8cf6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_468c4b71d20e4d6fbbc95190585f2826"}},"b84f066e4484423491ccef4a6c966579":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_299fb7c0e665459c89fb12a4c66f3ef8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":557,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":557,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81441509de454631b0bc75191481c99c"}},"f2e15342f93148b3808dc389531bb734":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0f65dee183e041d49cc7a7feec6999db","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 557/557 [00:00&lt;00:00, 14.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ee73f534f8134514a8547851ad760c5c"}},"70e6c5f263464d4a88572f5a405a8cf6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"468c4b71d20e4d6fbbc95190585f2826":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"299fb7c0e665459c89fb12a4c66f3ef8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"81441509de454631b0bc75191481c99c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0f65dee183e041d49cc7a7feec6999db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ee73f534f8134514a8547851ad760c5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"68366b2fe3e54dc0a45c50e8d8e02794":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b28ff0d3be9e45b0ad9f5681676b25c9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4034c8eb82824cc9bfbe672ef032055b","IPY_MODEL_11c56c32d25b49e297a436b857484a86","IPY_MODEL_b833be32a493421d9c43a328755a4a1f"]}},"b28ff0d3be9e45b0ad9f5681676b25c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4034c8eb82824cc9bfbe672ef032055b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6b62364d17694a138ebb1f11e87002f0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d8beb239b8414a2f9303a83b3c8c381d"}},"11c56c32d25b49e297a436b857484a86":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9a3928d511074bf5ae6ccbf704be1b1d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1208,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1208,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_576baff6c606490c912378f261043f55"}},"b833be32a493421d9c43a328755a4a1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7cddc4d540a44b9d96c5cc8e4b260ee9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.18k/1.18k [00:00&lt;00:00, 28.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cbb76940e4f54cc8a097de0573604f30"}},"6b62364d17694a138ebb1f11e87002f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d8beb239b8414a2f9303a83b3c8c381d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9a3928d511074bf5ae6ccbf704be1b1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"576baff6c606490c912378f261043f55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7cddc4d540a44b9d96c5cc8e4b260ee9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cbb76940e4f54cc8a097de0573604f30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6d5147bccb844078a560b24c13e9a413":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2c8575551a89432190cfd98a53f0fd83","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3f414af01b094671a45dbfea512db6b3","IPY_MODEL_31004974a6564b64a95f24a27683d39f","IPY_MODEL_9c3a54bf914e4bd1830e2e85051b4b89"]}},"2c8575551a89432190cfd98a53f0fd83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3f414af01b094671a45dbfea512db6b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dfb2d0bf3fb4417a8c2e320276f50227","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5ce6ff9097e843ef9043a291c438d43a"}},"31004974a6564b64a95f24a27683d39f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9ac11d31e48d4dc6a19707a0dbd45c42","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":891691413,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":891691413,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b3c65b8b3e64d05b6a051d7931b5e5b"}},"9c3a54bf914e4bd1830e2e85051b4b89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e2cd1996fd1b4d048b4f446449e1f3cb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 850M/850M [00:30&lt;00:00, 30.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89cda297fe7740e6803734b55c712c68"}},"dfb2d0bf3fb4417a8c2e320276f50227":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5ce6ff9097e843ef9043a291c438d43a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9ac11d31e48d4dc6a19707a0dbd45c42":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0b3c65b8b3e64d05b6a051d7931b5e5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e2cd1996fd1b4d048b4f446449e1f3cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"89cda297fe7740e6803734b55c712c68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"786a857e9263477480cc73e97531c0d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9148ac3e5127481c9594eaaf1d8087a2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_701192b6221d407cbb8778dacdb5f5ba","IPY_MODEL_de292e8a369d4803b90b31315969ae26","IPY_MODEL_8c5fe7fc4bee4c848c6395db752e7c62"]}},"9148ac3e5127481c9594eaaf1d8087a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"701192b6221d407cbb8778dacdb5f5ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b89d9b84d4a5492f8492bcacaa6e5290","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validation sanity check: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4136747131f64ab1812a5de5587c5882"}},"de292e8a369d4803b90b31315969ae26":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5d6293e974eb49dc89ca2ae1de760dd4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_08e20119e21645e9b3725b6fe44d3d46"}},"8c5fe7fc4bee4c848c6395db752e7c62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3fa0e3ba38a8448090584a19648e6aee","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5/5 [00:01&lt;00:00,  3.74it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8d7446318d104f79abd8d1f04b4c8fb5"}},"b89d9b84d4a5492f8492bcacaa6e5290":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4136747131f64ab1812a5de5587c5882":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d6293e974eb49dc89ca2ae1de760dd4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"08e20119e21645e9b3725b6fe44d3d46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3fa0e3ba38a8448090584a19648e6aee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8d7446318d104f79abd8d1f04b4c8fb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0fd13adec3994900b687fe097b4e84c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7a3349243a6945ef9ddad42b5cd3d26c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_34874fe784aa4f53ad7ba441a5974700","IPY_MODEL_74ce9434cd1e47ad8ded6fed10591099","IPY_MODEL_e4459f8472bd40138bd3fb6a8b7ab648"]}},"7a3349243a6945ef9ddad42b5cd3d26c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"34874fe784aa4f53ad7ba441a5974700":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f09bbfb45e1243918757eac5561dc36b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 2: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aed530ac420f450f8c4b46913390cd4d"}},"74ce9434cd1e47ad8ded6fed10591099":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_af6bf572bd8942cf829afeb61536d362","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1790,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1790,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_85d72f16208e40f49f5964d498eb2ab8"}},"e4459f8472bd40138bd3fb6a8b7ab648":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c6355f36ed554d418a08951876cf62c0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1790/1790 [27:46&lt;00:00,  1.07it/s, loss=nan, v_num=7, val_loss=nan]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_510c65906a5b4fa0b8f143292c4aa12b"}},"f09bbfb45e1243918757eac5561dc36b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aed530ac420f450f8c4b46913390cd4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af6bf572bd8942cf829afeb61536d362":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"85d72f16208e40f49f5964d498eb2ab8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c6355f36ed554d418a08951876cf62c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"510c65906a5b4fa0b8f143292c4aa12b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0fb57157fc643a58174283c69a2ecfb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ed0665e729414c08929e985d6569357a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b830386aad364485afe818e82a306c9a","IPY_MODEL_9ac9cf93517d4414ae9efad12a3eba08","IPY_MODEL_84559801582d4468bcdcbfbb0ffe9b2f"]}},"ed0665e729414c08929e985d6569357a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"b830386aad364485afe818e82a306c9a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0e695836c6db4eae9e3d8391f0ea89c3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_373a0167bc1e453f91b8c37ee3e73f7b"}},"9ac9cf93517d4414ae9efad12a3eba08":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f727ee9d2345478a91d060e68a2274af","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0d8484a26c2248ce90049b0fac28927e"}},"84559801582d4468bcdcbfbb0ffe9b2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ab3c802f8eee4ba3a0da428e94769117","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 358/358 [01:21&lt;00:00,  4.47it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d09ceabc21d94146ba0d882a2867f614"}},"0e695836c6db4eae9e3d8391f0ea89c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"373a0167bc1e453f91b8c37ee3e73f7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f727ee9d2345478a91d060e68a2274af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0d8484a26c2248ce90049b0fac28927e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab3c802f8eee4ba3a0da428e94769117":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d09ceabc21d94146ba0d882a2867f614":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e858d7eea959464788c0b4d9cffbbdca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_494209337f5b4d3187e786e2c403be7c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_85af391b84164b61aef6cd756397fd8a","IPY_MODEL_6f531cad304241d394a3930ef4d4776e","IPY_MODEL_6375cb05f4224ed887f02169928f992e"]}},"494209337f5b4d3187e786e2c403be7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"85af391b84164b61aef6cd756397fd8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7b0b9127549649fa95e1c3575620282a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d4cd5002372c4b8084d4064828202b91"}},"6f531cad304241d394a3930ef4d4776e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_700e09ff31f447b6b6f914962add2600","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac5aff94742243b5bc01796dd4df777d"}},"6375cb05f4224ed887f02169928f992e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_09f8f5e5ee5b44c48690780d8c69725a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 358/358 [01:20&lt;00:00,  4.47it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9efe213fd7c54e7f8c5d3101a80a620d"}},"7b0b9127549649fa95e1c3575620282a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d4cd5002372c4b8084d4064828202b91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"700e09ff31f447b6b6f914962add2600":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ac5aff94742243b5bc01796dd4df777d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"09f8f5e5ee5b44c48690780d8c69725a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9efe213fd7c54e7f8c5d3101a80a620d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0cf1a2139b94830a944fc95899d5734":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_631557f009c2470ea405d212e9659640","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_72cc0f753e37411da87b96e843a1a2cc","IPY_MODEL_f8dea0aa13cb46479d2c86cde21835f0","IPY_MODEL_28efbe0f4742469bb2eced8909c0a34f"]}},"631557f009c2470ea405d212e9659640":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72cc0f753e37411da87b96e843a1a2cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_be2846b4fe9446c792d365b2b2913b24","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0266fd4013ae4ccd8facc3e000367d4e"}},"f8dea0aa13cb46479d2c86cde21835f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4cc60e47775c4da9b7c61f98cb8327f2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":895321,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":895321,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_77db5b5380604e18b993caef9917cdd7"}},"28efbe0f4742469bb2eced8909c0a34f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a54cca7b7909446e9aae31275c0c6a30","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 874k/874k [00:00&lt;00:00, 3.91MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7ca697f1060f4780b49073b5d6fecc94"}},"be2846b4fe9446c792d365b2b2913b24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0266fd4013ae4ccd8facc3e000367d4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4cc60e47775c4da9b7c61f98cb8327f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"77db5b5380604e18b993caef9917cdd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a54cca7b7909446e9aae31275c0c6a30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7ca697f1060f4780b49073b5d6fecc94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87cc0c1c8f824b5a88dbe90219c2cc50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2831664a75eb4bd28813b0386b584c51","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d9dcb1f9b65a4cb195085de40053f128","IPY_MODEL_41339b75bbb342b28f4eb9b2f5e89cfb","IPY_MODEL_5248a530729f42739aebb473991cecbe"]}},"2831664a75eb4bd28813b0386b584c51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d9dcb1f9b65a4cb195085de40053f128":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_10600c6cea4a4ff9823393de89aabba4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_53df41c9a0844e019abe3d65f6180307"}},"41339b75bbb342b28f4eb9b2f5e89cfb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bdbaadf61df0499391fe163b5ae1db1c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1135173,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1135173,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_00dcfe16c6a445479ac63e1ec1faee28"}},"5248a530729f42739aebb473991cecbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c358f21aa15b4712adf70641aab76d6c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.08M/1.08M [00:00&lt;00:00, 1.56MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a22b08194d9b47b2a6c7143eb3f9255b"}},"10600c6cea4a4ff9823393de89aabba4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"53df41c9a0844e019abe3d65f6180307":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdbaadf61df0499391fe163b5ae1db1c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"00dcfe16c6a445479ac63e1ec1faee28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c358f21aa15b4712adf70641aab76d6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a22b08194d9b47b2a6c7143eb3f9255b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5b1c9156a9f421b8540de602854e7a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e28fc364069741a2aafe0e345d1b7b6e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_00479bdd78784ec989ca285557fa3e2d","IPY_MODEL_9f759653f8d644528402e2e7a230796a","IPY_MODEL_f1d681f96ea74dcd9f7227a0fc485c0f"]}},"e28fc364069741a2aafe0e345d1b7b6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"00479bdd78784ec989ca285557fa3e2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d071c388224c42969d66d88287eb944e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e7ef85c5af0242bcbc25d1869ee126f8"}},"9f759653f8d644528402e2e7a230796a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7d2994b929f5458c9fd1ad5bdf76b102","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":557,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":557,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_88a4727a098243fa8eab104babb4930c"}},"f1d681f96ea74dcd9f7227a0fc485c0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_75ddab400c9b4ecb87a7c7311aee5079","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 557/557 [00:00&lt;00:00, 14.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dc9a96835a3d4caabc95ac395938c4bf"}},"d071c388224c42969d66d88287eb944e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e7ef85c5af0242bcbc25d1869ee126f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d2994b929f5458c9fd1ad5bdf76b102":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"88a4727a098243fa8eab104babb4930c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75ddab400c9b4ecb87a7c7311aee5079":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dc9a96835a3d4caabc95ac395938c4bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"PlNF-_DjfgtK"},"source":["\n","# **Install libraries**"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j-Cd_cNmKbkz","executionInfo":{"status":"ok","timestamp":1639738674404,"user_tz":-420,"elapsed":4042,"user":{"displayName":"Nghiem Hoa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02320684392395045478"}},"outputId":"ed589129-6d0c-4a87-d1bf-27957d92460f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"],"metadata":{"id":"1XAcu_VvYB3A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# Chi Hoa xinh dep\n","os.chdir('/content/drive/Shareddrives/hoa.lenghiem/ThanhQuang_NLP/')\n","# os.chdir('/content/drive/MyDrive/VIN_NLP/ThanhQuang_NLP/')"],"metadata":{"id":"l2CdS0zpO0Sd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Installing library"],"metadata":{"id":"pI8Obc_eYUko"}},{"cell_type":"code","source":["import pytorch_lightning as pl\n","pl.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"xJhEovcUAT6P","executionInfo":{"status":"ok","timestamp":1639738689363,"user_tz":-420,"elapsed":821,"user":{"displayName":"Nghiem Hoa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02320684392395045478"}},"outputId":"af8568e8-7626-4652-f9f5-c896e23398bf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'0.7.5'"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"vE1wWifoDu3Y","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6060b0f1-c8e9-42de-8195-8d056c979663","executionInfo":{"status":"ok","timestamp":1639738518967,"user_tz":-420,"elapsed":204982,"user":{"displayName":"Nghiem Hoa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02320684392395045478"}}},"source":["!pip install pytorch_lightning==0.7.5\n","!pip install SentencePiece\n","!pip install transformers\n","!pip install torch==1.5.0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_lightning==0.7.5\n","  Downloading pytorch_lightning-0.7.5-py3-none-any.whl (233 kB)\n","\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 92 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 233 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==0.7.5) (1.10.0+cu111)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==0.7.5) (4.62.3)\n","Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==0.7.5) (2.7.0)\n","Collecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 55.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==0.7.5) (1.19.5)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.37.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.35.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (57.4.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.8.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.42.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.4.6)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (3.17.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (0.12.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch_lightning==0.7.5) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=1.14->pytorch_lightning==0.7.5) (1.15.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.7.5) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch_lightning==0.7.5) (4.8.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.6.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.7.5) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch_lightning==0.7.5) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.7.5) (3.1.1)\n","Building wheels for collected packages: future\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=6d41bed689de9c8e708c6ee9f638bca48816c9e82f6e80e9cd04e20cc5060e95\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","Successfully built future\n","Installing collected packages: future, pytorch-lightning\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","Successfully installed future-0.18.2 pytorch-lightning-0.7.5\n","Collecting SentencePiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 5.0 MB/s \n","\u001b[?25hInstalling collected packages: SentencePiece\n","Successfully installed SentencePiece-0.1.96\n","Collecting transformers\n","  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 417 kB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 50.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 57.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 54.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.14.1\n","Collecting torch==1.5.0\n","  Downloading torch-1.5.0-cp37-cp37m-manylinux1_x86_64.whl (752.0 MB)\n","\u001b[K     |████████████████████████████████| 752.0 MB 7.8 kB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0) (0.18.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0) (1.19.5)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.5.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.5.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"H0n55Ex1Bl2k"},"source":["# **Import packages**"]},{"cell_type":"code","metadata":{"id":"m5WiQS6FEEsL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2ad5755e-f1a7-440b-e4ef-9416d017e571","executionInfo":{"status":"ok","timestamp":1639738701937,"user_tz":-420,"elapsed":6457,"user":{"displayName":"Nghiem Hoa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02320684392395045478"}}},"source":["import argparse\n","import glob\n","import os\n","import json\n","import time\n","import logging\n","import random\n","import re\n","from itertools import chain\n","from string import punctuation\n","\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import pytorch_lightning as pl\n","\n","from transformers import (\n","    AdamW,\n","    T5ForConditionalGeneration,\n","    PhobertTokenizer,\n","    get_linear_schedule_with_warmup\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ykds8V47B1XT"},"source":["# **Set a seed**"]},{"cell_type":"code","metadata":{"id":"CyrYjMFREUCn"},"source":["def set_seed(seed):\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","\n","set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8uSCxnPmCALw"},"source":["# **T5FineTuner**"]},{"cell_type":"code","metadata":{"id":"Zr7mnuYEEhxn"},"source":["class T5FineTuner(pl.LightningModule):\n","    def __init__(self, hparams):\n","        super(T5FineTuner, self).__init__()\n","        self.hparams = hparams\n","\n","        self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n","        self.tokenizer = AutoTokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n","\n","    def is_logger(self):\n","        return True #self.trainer.proc_rank <= 0\n","\n","    def forward(\n","            self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None\n","    ):\n","        return self.model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            decoder_input_ids=decoder_input_ids,\n","            decoder_attention_mask=decoder_attention_mask,\n","            labels=labels,\n","        )\n","\n","    def _step(self, batch):\n","        labels = batch[\"target_ids\"]\n","        labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n","\n","        outputs = self(\n","            input_ids=batch[\"source_ids\"],\n","            attention_mask=batch[\"source_mask\"],\n","            labels=labels,\n","            decoder_attention_mask=batch['target_mask']\n","        )\n","\n","        loss = outputs[0]\n","\n","        return loss\n","\n","    def training_step(self, batch, batch_idx):\n","        loss = self._step(batch)\n","\n","        tensorboard_logs = {\"train_loss\": loss}\n","        return {\"loss\": loss, \"log\": tensorboard_logs}\n","\n","    def training_epoch_end(self, outputs):\n","        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n","        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n","        return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n","\n","    def validation_step(self, batch, batch_idx):\n","        loss = self._step(batch)\n","        return {\"val_loss\": loss}\n","\n","    def validation_epoch_end(self, outputs):\n","        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n","        tensorboard_logs = {\"val_loss\": avg_loss}\n","        return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n","\n","    def configure_optimizers(self):\n","        \"Prepare optimizer and schedule (linear warmup and decay)\"\n","\n","        model = self.model\n","        no_decay = [\"bias\", \"LayerNorm.weight\"]\n","        optimizer_grouped_parameters = [\n","            {\n","                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": self.hparams.weight_decay,\n","            },\n","            {\n","                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","        optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n","        self.opt = optimizer\n","        return [optimizer]\n","\n","    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None, on_tpu=False, using_native_amp=False, using_lbfgs=False):\n","        if self.trainer.use_tpu:\n","            xm.optimizer_step(optimizer)\n","        else:\n","            optimizer.step()\n","        optimizer.zero_grad()\n","        self.lr_scheduler.step()\n","\n","    def get_tqdm_dict(self):\n","        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n","\n","        return tqdm_dict\n","\n","    def train_dataloader(self):\n","        train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"sampling_train_tok\", args=self.hparams)\n","        dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True,\n","                                num_workers=4)\n","        t_total = (\n","                (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n","                // self.hparams.gradient_accumulation_steps\n","                * float(self.hparams.num_train_epochs)\n","        )\n","        scheduler = get_linear_schedule_with_warmup(\n","            self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n","        )\n","        self.lr_scheduler = scheduler\n","        return dataloader\n","\n","    def val_dataloader(self):\n","        val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"sampling_val_tok\", args=self.hparams)\n","        return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n","\n","logger = logging.getLogger(__name__)\n","\n","class LoggingCallback(pl.Callback):\n","  def on_validation_end(self, trainer, pl_module):\n","    logger.info(\"***** Validation results *****\")\n","    if pl_module.is_logger():\n","      metrics = trainer.callback_metrics\n","      # Log results\n","      for key in sorted(metrics):\n","        if key not in [\"log\", \"progress_bar\"]:\n","          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n","\n","  def on_test_end(self, trainer, pl_module):\n","    logger.info(\"***** Test results *****\")\n","\n","    if pl_module.is_logger():\n","      metrics = trainer.callback_metrics\n","\n","      # Log and save results to file\n","      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n","      with open(output_test_results_file, \"w\") as writer:\n","        for key in sorted(metrics):\n","          if key not in [\"log\", \"progress_bar\"]:\n","            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n","            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","DEVICE"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"3U5EtPMbOJHq","executionInfo":{"status":"ok","timestamp":1639738145886,"user_tz":-420,"elapsed":338,"user":{"displayName":"Nghiem Hoa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02320684392395045478"}},"outputId":"b59837f3-4c94-4ee3-c349-f1b5f66a6a1e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'cuda'"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"2nsjLzviCG_A"},"source":["# **Load datasets**"]},{"cell_type":"code","source":["import pandas as pd\n","data_train = pd.read_csv(\"merge_pair_sentence_dataset/sampling_train_tok.csv\")#.astype(str)\n","data_dev = pd.read_csv(\"merge_pair_sentence_dataset/sampling_val_tok.csv\")#.astype(str)\n","data_test = pd.read_csv(\"merge_pair_sentence_dataset/sampling_test_tok.csv\")#.astype(str)\n"],"metadata":{"id":"h2wgXIt24fHS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t4eRy5oVCUny"},"source":["# **Set arguments**"]},{"cell_type":"code","metadata":{"id":"7UZzosIjEr8I","colab":{"base_uri":"https://localhost:8080/","height":235,"referenced_widgets":["e253737e7ce849b389d367539b0523d8","d4d8898f045145afa12d74cee9d4867d","2be4d04a3dc942f2b2040da9764c35d4","531f0354d13540d2b8688ad7d48ba0c5","cd585de115b8405aaaf9bb3c0f422311","48a13e3dbda3486b8c1475baf8870145","cfbe1ce74694446fbd52d79f98fd4f48","67be98ee20ce4ab5ae766693b20388bb","6f29a205110c44dd846ef220aedf5ee7","167b6ef29a474dbbac77709a7beff082","c76efb6c14074a1492b2df79a37da9df","71a12c93345c4b839d7d7e9408ddf8b3","3f76f7ee65754daa8ca80273ded9bcc4","f79800aa5ba44e3f8b4a790dc912aac2","bffbb6963bfb4a49993ea5c73ef0fa68","fb08cb45b7a94fe8912a2492e9606acd","6e5806f9bdc44491bf66b57bee4b792a","be528583d8b04fcb94e6e524270e709c","ae55530a9dc44bf1b4f07277247ef0c3","64ff58c73395445aae64259786d1ede2","f2de31c780944d7fa6d6e131bcd7a076","2e30728a25d846109e0c60261adc01e0","8f5582015f8e4380b21d9c11c279cb78","60761fe69c8449788a3e649c0a7a3c71","91d5edc1ae89469fb413dac19bbc0a14","b84f066e4484423491ccef4a6c966579","f2e15342f93148b3808dc389531bb734","70e6c5f263464d4a88572f5a405a8cf6","468c4b71d20e4d6fbbc95190585f2826","299fb7c0e665459c89fb12a4c66f3ef8","81441509de454631b0bc75191481c99c","0f65dee183e041d49cc7a7feec6999db","ee73f534f8134514a8547851ad760c5c"]},"outputId":"000d56de-6acf-4cda-ffa8-cd4c9002d23b","executionInfo":{"status":"ok","timestamp":1639733144462,"user_tz":-420,"elapsed":3048,"user":{"displayName":"Nghiem Hoa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02320684392395045478"}}},"source":["args_dict = dict(\n","    # data_dir=\"/content/drive/Shareddrives/hoa.lenghiem/ThanhQuang_NLP/merge_pair_sentence_dataset/\", # path for data files\n","    data_dir=\"merge_pair_sentence_dataset\", # path for data files\n","    output_dir=\"save_check_point\", # path to save the checkpoints\n","    model_name_or_path='ramsrigouthamg/t5_paraphraser',\n","    tokenizer_name_or_path='vinai/phobert-base',\n","    # max_seq_length=64,\n","    max_seq_length=256,\n","    learning_rate=3e-4,\n","    weight_decay=0.0,\n","    adam_epsilon=1e-8,\n","    warmup_steps=0,\n","    train_batch_size=4,\n","    eval_batch_size=2,\n","    num_train_epochs=2,\n","    gradient_accumulation_steps=16,\n","    n_gpu=1,\n","    early_stop_callback=False,\n","    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n","    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n","    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n","    seed=42,\n",")\n","\n","train_path = \"merge_pair_sentence_dataset/sampling_train_tok.csv\"\n","val_path = \"merge_pair_sentence_dataset/sampling_val_tok.csv\"\n","\n","train = pd.read_csv(train_path)\n","print(train.head())\n","\n","tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                       sentence1_tok                                      sentence2_tok\n","0  Ken ( sinh năm 1963 tại New_Jersey ) là một bú...  Ken ( sinh khoảng khoảng năm 1963 ở New_Jersey...\n","1  Phon_Sai là một huyện ( ' amphoe ' ) ở phía bắ...  Phon_Sai là một huyện ( ' Amophoe ' ) ở phía đ...\n","2  Hai đứa còn lại là con cuối của Robert_Hammond...  Nathaniel_Hammond , qua_đời năm 1906 , và Rich...\n","3  John Barrow Island là một thành_viên của quần_...  John Barrow Island là một thành_viên của Đại_h...\n","4      Những người phụ_nữ đang đá bóng trên sân_cỏ .  Hai đội bóng_đá nữ đang chơi trên sân_cỏ trước...\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e253737e7ce849b389d367539b0523d8","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/874k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71a12c93345c4b839d7d7e9408ddf8b3","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f5582015f8e4380b21d9c11c279cb78","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/557 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"markdown","metadata":{"id":"_p5OZ7pRCel5"},"source":["# **ParaphraseDataset()**"]},{"cell_type":"code","metadata":{"id":"E5UwYTUAGAo2"},"source":["class ParaphraseDataset(Dataset):\n","    def __init__(self, tokenizer, data_dir, type_path, max_len=512):\n","        self.path = os.path.join(data_dir, type_path + '.csv')\n","\n","        self.source_column = \"sentence1_tok\"\n","        self.target_column = \"sentence2_tok\"\n","        self.data = pd.read_csv(self.path)\n","\n","        self.max_len = max_len\n","        self.tokenizer = tokenizer\n","        self.inputs = []\n","        self.targets = []\n","\n","        self._build()\n","\n","    def __len__(self):\n","        return len(self.inputs)\n","\n","    def __getitem__(self, index):\n","        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n","        target_ids = self.targets[index][\"input_ids\"].squeeze()\n","\n","        src_mask = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n","        target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n","\n","        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n","\n","    def _build(self):\n","        for idx in range(len(self.data)):\n","            input_, target = self.data.loc[idx, self.source_column], self.data.loc[idx, self.target_column]\n","\n","            # input_ = \"paraphrase: \"+ input_ + ' </s>'\n","            # target = target + \" </s>\"\n","\n","            # tokenize inputs\n","            tokenized_inputs = self.tokenizer.batch_encode_plus(\n","                [input_], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\", truncation='longest_first'\n","            )\n","            # tokenize targets\n","            tokenized_targets = self.tokenizer.batch_encode_plus(\n","                [target], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\", truncation='longest_first'\n","            )\n","\n","            self.inputs.append(tokenized_inputs)\n","            self.targets.append(tokenized_targets)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gkVUkHFMClrH"},"source":["# **Start training**"]},{"cell_type":"code","source":["# import torch\n","# torch.cuda.empty_cache()"],"metadata":{"id":"5-U--6NR9gdd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = ParaphraseDataset(tokenizer, \n","                            'merge_pair_sentence_dataset', \n","                            'sampling_val_tok', 256)\n","print(\"Val dataset: \",len(dataset))\n","\n","data = dataset[61]\n","print(tokenizer.decode(data['source_ids']))\n","print(tokenizer.decode(data['target_ids']))\n","\n","if not os.path.exists('save_check_point'):\n","    os.makedirs('save_check_point')\n","\n","# args_dict.update({'data_dir': 'merge_pair_sentence_dataset', \n","#                   'output_dir': 'save_check_point', 'num_train_epochs':20,'max_seq_length':256})\n","args = argparse.Namespace(**args_dict)\n","print(args_dict)\n","\n","\n","\n","checkpoint_callback = pl.callbacks.model_checkpoint.ModelCheckpoint(\n","    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",")\n","\n","train_params = dict(\n","    accumulate_grad_batches=args.gradient_accumulation_steps,\n","    gpus=args.n_gpu,\n","    max_epochs=args.num_train_epochs,\n"," #   early_stop_callback=False,\n","    precision= 16 if args.fp_16 else 32,\n","    amp_level=args.opt_level,\n","    gradient_clip_val=args.max_grad_norm,\n","    checkpoint_callback=checkpoint_callback,\n","    callbacks=[LoggingCallback()],\n","    # Chi Hoa xinh dep\n","    default_root_dir='/content/drive/Shareddrives/hoa.lenghiem/ThanhQuang_NLP/'\n","    \n","    # default_root_dir='/content/drive/MyDrive/VIN_NLP/ThanhQuang_NLP'\n","\n",")\n","\n","def get_dataset(tokenizer, type_path, args):\n","  return ParaphraseDataset(tokenizer=tokenizer, data_dir=args.data_dir, \n","                           type_path=type_path,  max_len=args.max_seq_length)\n","\n","print (\"Initialize model\")\n","model = T5FineTuner(args)\n","\n","trainer = pl.Trainer(**train_params)\n","\n","print (\" Training model\")\n","trainer.fit(model)\n","\n","\n","print (\"training finished\")\n","\n","print (\"Saving model\")\n","model.model.save_pretrained('save_check_point')\n","\n","print (\"Model saved\")\n","\n","# !cp \"/content/t5_paraphrase/\" -a \"/content/drive/My Drive/\"\n","# !cp \"/content/lightning_logs/\" -a \"/content/drive/My Drive/\"\n","# print (\"Copied the final folder to Google Drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["68366b2fe3e54dc0a45c50e8d8e02794","b28ff0d3be9e45b0ad9f5681676b25c9","4034c8eb82824cc9bfbe672ef032055b","11c56c32d25b49e297a436b857484a86","b833be32a493421d9c43a328755a4a1f","6b62364d17694a138ebb1f11e87002f0","d8beb239b8414a2f9303a83b3c8c381d","9a3928d511074bf5ae6ccbf704be1b1d","576baff6c606490c912378f261043f55","7cddc4d540a44b9d96c5cc8e4b260ee9","cbb76940e4f54cc8a097de0573604f30","6d5147bccb844078a560b24c13e9a413","2c8575551a89432190cfd98a53f0fd83","3f414af01b094671a45dbfea512db6b3","31004974a6564b64a95f24a27683d39f","9c3a54bf914e4bd1830e2e85051b4b89","dfb2d0bf3fb4417a8c2e320276f50227","5ce6ff9097e843ef9043a291c438d43a","9ac11d31e48d4dc6a19707a0dbd45c42","0b3c65b8b3e64d05b6a051d7931b5e5b","e2cd1996fd1b4d048b4f446449e1f3cb","89cda297fe7740e6803734b55c712c68","786a857e9263477480cc73e97531c0d0","9148ac3e5127481c9594eaaf1d8087a2","701192b6221d407cbb8778dacdb5f5ba","de292e8a369d4803b90b31315969ae26","8c5fe7fc4bee4c848c6395db752e7c62","b89d9b84d4a5492f8492bcacaa6e5290","4136747131f64ab1812a5de5587c5882","5d6293e974eb49dc89ca2ae1de760dd4","08e20119e21645e9b3725b6fe44d3d46","3fa0e3ba38a8448090584a19648e6aee","8d7446318d104f79abd8d1f04b4c8fb5","0fd13adec3994900b687fe097b4e84c8","7a3349243a6945ef9ddad42b5cd3d26c","34874fe784aa4f53ad7ba441a5974700","74ce9434cd1e47ad8ded6fed10591099","e4459f8472bd40138bd3fb6a8b7ab648","f09bbfb45e1243918757eac5561dc36b","aed530ac420f450f8c4b46913390cd4d","af6bf572bd8942cf829afeb61536d362","85d72f16208e40f49f5964d498eb2ab8","c6355f36ed554d418a08951876cf62c0","510c65906a5b4fa0b8f143292c4aa12b","c0fb57157fc643a58174283c69a2ecfb","ed0665e729414c08929e985d6569357a","b830386aad364485afe818e82a306c9a","9ac9cf93517d4414ae9efad12a3eba08","84559801582d4468bcdcbfbb0ffe9b2f","0e695836c6db4eae9e3d8391f0ea89c3","373a0167bc1e453f91b8c37ee3e73f7b","f727ee9d2345478a91d060e68a2274af","0d8484a26c2248ce90049b0fac28927e","ab3c802f8eee4ba3a0da428e94769117","d09ceabc21d94146ba0d882a2867f614","e858d7eea959464788c0b4d9cffbbdca","494209337f5b4d3187e786e2c403be7c","85af391b84164b61aef6cd756397fd8a","6f531cad304241d394a3930ef4d4776e","6375cb05f4224ed887f02169928f992e","7b0b9127549649fa95e1c3575620282a","d4cd5002372c4b8084d4064828202b91","700e09ff31f447b6b6f914962add2600","ac5aff94742243b5bc01796dd4df777d","09f8f5e5ee5b44c48690780d8c69725a","9efe213fd7c54e7f8c5d3101a80a620d"]},"id":"yw0HERviXNkC","outputId":"7c06125b-6be4-46ce-e821-0985747eb392","executionInfo":{"status":"ok","timestamp":1639736577547,"user_tz":-420,"elapsed":3150066,"user":{"displayName":"Nghiem Hoa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02320684392395045478"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Val dataset:  716\n","<s> Một cô bé đang chơi thả diều ở trên bãi biển. </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n","<s> Cô bé áo hồng đang chơi thả diều ở trên bãi biển. </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n","{'data_dir': 'merge_pair_sentence_dataset', 'output_dir': 'save_check_point', 'model_name_or_path': 'ramsrigouthamg/t5_paraphraser', 'tokenizer_name_or_path': 'vinai/phobert-base', 'max_seq_length': 256, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'train_batch_size': 4, 'eval_batch_size': 2, 'num_train_epochs': 2, 'gradient_accumulation_steps': 16, 'n_gpu': 1, 'early_stop_callback': False, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42}\n","Initialize model\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68366b2fe3e54dc0a45c50e8d8e02794","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d5147bccb844078a560b24c13e9a413","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","INFO:lightning:GPU available: True, used: True\n","INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":[" Training model\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:lightning:\n","    | Name                                                                | Type                       | Params\n","---------------------------------------------------------------------------------------------------------------\n","0   | model                                                               | T5ForConditionalGeneration | 222 M \n","1   | model.shared                                                        | Embedding                  | 24 M  \n","2   | model.encoder                                                       | T5Stack                    | 109 M \n","3   | model.encoder.block                                                 | ModuleList                 | 84 M  \n","4   | model.encoder.block.0                                               | T5Block                    | 7 M   \n","5   | model.encoder.block.0.layer                                         | ModuleList                 | 7 M   \n","6   | model.encoder.block.0.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","7   | model.encoder.block.0.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","8   | model.encoder.block.0.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","9   | model.encoder.block.0.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","10  | model.encoder.block.0.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","11  | model.encoder.block.0.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","12  | model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias | Embedding                  | 384   \n","13  | model.encoder.block.0.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","14  | model.encoder.block.0.layer.0.dropout                               | Dropout                    | 0     \n","15  | model.encoder.block.0.layer.1                                       | T5LayerFF                  | 4 M   \n","16  | model.encoder.block.0.layer.1.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","17  | model.encoder.block.0.layer.1.DenseReluDense.wi                     | Linear                     | 2 M   \n","18  | model.encoder.block.0.layer.1.DenseReluDense.wo                     | Linear                     | 2 M   \n","19  | model.encoder.block.0.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","20  | model.encoder.block.0.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","21  | model.encoder.block.0.layer.1.dropout                               | Dropout                    | 0     \n","22  | model.encoder.block.1                                               | T5Block                    | 7 M   \n","23  | model.encoder.block.1.layer                                         | ModuleList                 | 7 M   \n","24  | model.encoder.block.1.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","25  | model.encoder.block.1.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","26  | model.encoder.block.1.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","27  | model.encoder.block.1.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","28  | model.encoder.block.1.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","29  | model.encoder.block.1.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","30  | model.encoder.block.1.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","31  | model.encoder.block.1.layer.0.dropout                               | Dropout                    | 0     \n","32  | model.encoder.block.1.layer.1                                       | T5LayerFF                  | 4 M   \n","33  | model.encoder.block.1.layer.1.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","34  | model.encoder.block.1.layer.1.DenseReluDense.wi                     | Linear                     | 2 M   \n","35  | model.encoder.block.1.layer.1.DenseReluDense.wo                     | Linear                     | 2 M   \n","36  | model.encoder.block.1.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","37  | model.encoder.block.1.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","38  | model.encoder.block.1.layer.1.dropout                               | Dropout                    | 0     \n","39  | model.encoder.block.2                                               | T5Block                    | 7 M   \n","40  | model.encoder.block.2.layer                                         | ModuleList                 | 7 M   \n","41  | model.encoder.block.2.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","42  | model.encoder.block.2.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","43  | model.encoder.block.2.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","44  | model.encoder.block.2.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","45  | model.encoder.block.2.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","46  | model.encoder.block.2.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","47  | model.encoder.block.2.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","48  | model.encoder.block.2.layer.0.dropout                               | Dropout                    | 0     \n","49  | model.encoder.block.2.layer.1                                       | T5LayerFF                  | 4 M   \n","50  | model.encoder.block.2.layer.1.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","51  | model.encoder.block.2.layer.1.DenseReluDense.wi                     | Linear                     | 2 M   \n","52  | model.encoder.block.2.layer.1.DenseReluDense.wo                     | Linear                     | 2 M   \n","53  | model.encoder.block.2.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","54  | model.encoder.block.2.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","55  | model.encoder.block.2.layer.1.dropout                               | Dropout                    | 0     \n","56  | model.encoder.block.3                                               | T5Block                    | 7 M   \n","57  | model.encoder.block.3.layer                                         | ModuleList                 | 7 M   \n","58  | model.encoder.block.3.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","59  | model.encoder.block.3.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","60  | model.encoder.block.3.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","61  | model.encoder.block.3.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","62  | model.encoder.block.3.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","63  | model.encoder.block.3.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","64  | model.encoder.block.3.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","65  | model.encoder.block.3.layer.0.dropout                               | Dropout                    | 0     \n","66  | model.encoder.block.3.layer.1                                       | T5LayerFF                  | 4 M   \n","67  | model.encoder.block.3.layer.1.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","68  | model.encoder.block.3.layer.1.DenseReluDense.wi                     | Linear                     | 2 M   \n","69  | model.encoder.block.3.layer.1.DenseReluDense.wo                     | Linear                     | 2 M   \n","70  | model.encoder.block.3.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","71  | model.encoder.block.3.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","72  | model.encoder.block.3.layer.1.dropout                               | Dropout                    | 0     \n","73  | model.encoder.block.4                                               | T5Block                    | 7 M   \n","74  | model.encoder.block.4.layer                                         | ModuleList                 | 7 M   \n","75  | model.encoder.block.4.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","76  | model.encoder.block.4.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","77  | model.encoder.block.4.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","78  | model.encoder.block.4.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","79  | model.encoder.block.4.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","80  | model.encoder.block.4.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","81  | model.encoder.block.4.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","82  | model.encoder.block.4.layer.0.dropout                               | Dropout                    | 0     \n","83  | model.encoder.block.4.layer.1                                       | T5LayerFF                  | 4 M   \n","84  | model.encoder.block.4.layer.1.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","85  | model.encoder.block.4.layer.1.DenseReluDense.wi                     | Linear                     | 2 M   \n","86  | model.encoder.block.4.layer.1.DenseReluDense.wo                     | Linear                     | 2 M   \n","87  | model.encoder.block.4.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","88  | model.encoder.block.4.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","89  | model.encoder.block.4.layer.1.dropout                               | Dropout                    | 0     \n","90  | model.encoder.block.5                                               | T5Block                    | 7 M   \n","91  | model.encoder.block.5.layer                                         | ModuleList                 | 7 M   \n","92  | model.encoder.block.5.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","93  | model.encoder.block.5.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","94  | model.encoder.block.5.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","95  | model.encoder.block.5.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","96  | model.encoder.block.5.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","97  | model.encoder.block.5.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","98  | model.encoder.block.5.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","99  | model.encoder.block.5.layer.0.dropout                               | Dropout                    | 0     \n","100 | model.encoder.block.5.layer.1                                       | T5LayerFF                  | 4 M   \n","101 | model.encoder.block.5.layer.1.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","102 | model.encoder.block.5.layer.1.DenseReluDense.wi                     | Linear                     | 2 M   \n","103 | model.encoder.block.5.layer.1.DenseReluDense.wo                     | Linear                     | 2 M   \n","104 | model.encoder.block.5.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","105 | model.encoder.block.5.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","106 | model.encoder.block.5.layer.1.dropout                               | Dropout                    | 0     \n","107 | model.encoder.block.6                                               | T5Block                    | 7 M   \n","108 | model.encoder.block.6.layer                                         | ModuleList                 | 7 M   \n","109 | model.encoder.block.6.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","110 | model.encoder.block.6.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","111 | model.encoder.block.6.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","112 | model.encoder.block.6.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","113 | model.encoder.block.6.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","114 | model.encoder.block.6.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","115 | model.encoder.block.6.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","116 | model.encoder.block.6.layer.0.dropout                               | Dropout                    | 0     \n","117 | model.encoder.block.6.layer.1                                       | T5LayerFF                  | 4 M   \n","118 | model.encoder.block.6.layer.1.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","119 | model.encoder.block.6.layer.1.DenseReluDense.wi                     | Linear                     | 2 M   \n","120 | model.encoder.block.6.layer.1.DenseReluDense.wo                     | Linear                     | 2 M   \n","121 | model.encoder.block.6.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","122 | model.encoder.block.6.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","123 | model.encoder.block.6.layer.1.dropout                               | Dropout                    | 0     \n","124 | model.encoder.block.7                                               | T5Block                    | 7 M   \n","125 | model.encoder.block.7.layer                                         | ModuleList                 | 7 M   \n","126 | model.encoder.block.7.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","127 | model.encoder.block.7.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","128 | model.encoder.block.7.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","129 | model.encoder.block.7.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","130 | model.encoder.block.7.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","131 | model.encoder.block.7.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","132 | model.encoder.block.7.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","133 | model.encoder.block.7.layer.0.dropout                               | Dropout                    | 0     \n","134 | model.encoder.block.7.layer.1                                       | T5LayerFF                  | 4 M   \n","135 | model.encoder.block.7.layer.1.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","136 | model.encoder.block.7.layer.1.DenseReluDense.wi                     | Linear                     | 2 M   \n","137 | model.encoder.block.7.layer.1.DenseReluDense.wo                     | Linear                     | 2 M   \n","138 | model.encoder.block.7.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","139 | model.encoder.block.7.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","140 | model.encoder.block.7.layer.1.dropout                               | Dropout                    | 0     \n","141 | model.encoder.block.8                                               | T5Block                    | 7 M   \n","142 | model.encoder.block.8.layer                                         | ModuleList                 | 7 M   \n","143 | model.encoder.block.8.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","144 | model.encoder.block.8.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","145 | model.encoder.block.8.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","146 | model.encoder.block.8.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","147 | model.encoder.block.8.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","148 | model.encoder.block.8.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","149 | model.encoder.block.8.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","150 | model.encoder.block.8.layer.0.dropout                               | Dropout                    | 0     \n","151 | model.encoder.block.8.layer.1                                       | T5LayerFF                  | 4 M   \n","152 | model.encoder.block.8.layer.1.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","153 | model.encoder.block.8.layer.1.DenseReluDense.wi                     | Linear                     | 2 M   \n","154 | model.encoder.block.8.layer.1.DenseReluDense.wo                     | Linear                     | 2 M   \n","155 | model.encoder.block.8.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","156 | model.encoder.block.8.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","157 | model.encoder.block.8.layer.1.dropout                               | Dropout                    | 0     \n","158 | model.encoder.block.9                                               | T5Block                    | 7 M   \n","159 | model.encoder.block.9.layer                                         | ModuleList                 | 7 M   \n","160 | model.encoder.block.9.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","161 | model.encoder.block.9.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","162 | model.encoder.block.9.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","163 | model.encoder.block.9.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","164 | model.encoder.block.9.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","165 | model.encoder.block.9.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","166 | model.encoder.block.9.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","167 | model.encoder.block.9.layer.0.dropout                               | Dropout                    | 0     \n","168 | model.encoder.block.9.layer.1                                       | T5LayerFF                  | 4 M   \n","169 | model.encoder.block.9.layer.1.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","170 | model.encoder.block.9.layer.1.DenseReluDense.wi                     | Linear                     | 2 M   \n","171 | model.encoder.block.9.layer.1.DenseReluDense.wo                     | Linear                     | 2 M   \n","172 | model.encoder.block.9.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","173 | model.encoder.block.9.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","174 | model.encoder.block.9.layer.1.dropout                               | Dropout                    | 0     \n","175 | model.encoder.block.10                                              | T5Block                    | 7 M   \n","176 | model.encoder.block.10.layer                                        | ModuleList                 | 7 M   \n","177 | model.encoder.block.10.layer.0                                      | T5LayerSelfAttention       | 2 M   \n","178 | model.encoder.block.10.layer.0.SelfAttention                        | T5Attention                | 2 M   \n","179 | model.encoder.block.10.layer.0.SelfAttention.q                      | Linear                     | 589 K \n","180 | model.encoder.block.10.layer.0.SelfAttention.k                      | Linear                     | 589 K \n","181 | model.encoder.block.10.layer.0.SelfAttention.v                      | Linear                     | 589 K \n","182 | model.encoder.block.10.layer.0.SelfAttention.o                      | Linear                     | 589 K \n","183 | model.encoder.block.10.layer.0.layer_norm                           | T5LayerNorm                | 768   \n","184 | model.encoder.block.10.layer.0.dropout                              | Dropout                    | 0     \n","185 | model.encoder.block.10.layer.1                                      | T5LayerFF                  | 4 M   \n","186 | model.encoder.block.10.layer.1.DenseReluDense                       | T5DenseReluDense           | 4 M   \n","187 | model.encoder.block.10.layer.1.DenseReluDense.wi                    | Linear                     | 2 M   \n","188 | model.encoder.block.10.layer.1.DenseReluDense.wo                    | Linear                     | 2 M   \n","189 | model.encoder.block.10.layer.1.DenseReluDense.dropout               | Dropout                    | 0     \n","190 | model.encoder.block.10.layer.1.layer_norm                           | T5LayerNorm                | 768   \n","191 | model.encoder.block.10.layer.1.dropout                              | Dropout                    | 0     \n","192 | model.encoder.block.11                                              | T5Block                    | 7 M   \n","193 | model.encoder.block.11.layer                                        | ModuleList                 | 7 M   \n","194 | model.encoder.block.11.layer.0                                      | T5LayerSelfAttention       | 2 M   \n","195 | model.encoder.block.11.layer.0.SelfAttention                        | T5Attention                | 2 M   \n","196 | model.encoder.block.11.layer.0.SelfAttention.q                      | Linear                     | 589 K \n","197 | model.encoder.block.11.layer.0.SelfAttention.k                      | Linear                     | 589 K \n","198 | model.encoder.block.11.layer.0.SelfAttention.v                      | Linear                     | 589 K \n","199 | model.encoder.block.11.layer.0.SelfAttention.o                      | Linear                     | 589 K \n","200 | model.encoder.block.11.layer.0.layer_norm                           | T5LayerNorm                | 768   \n","201 | model.encoder.block.11.layer.0.dropout                              | Dropout                    | 0     \n","202 | model.encoder.block.11.layer.1                                      | T5LayerFF                  | 4 M   \n","203 | model.encoder.block.11.layer.1.DenseReluDense                       | T5DenseReluDense           | 4 M   \n","204 | model.encoder.block.11.layer.1.DenseReluDense.wi                    | Linear                     | 2 M   \n","205 | model.encoder.block.11.layer.1.DenseReluDense.wo                    | Linear                     | 2 M   \n","206 | model.encoder.block.11.layer.1.DenseReluDense.dropout               | Dropout                    | 0     \n","207 | model.encoder.block.11.layer.1.layer_norm                           | T5LayerNorm                | 768   \n","208 | model.encoder.block.11.layer.1.dropout                              | Dropout                    | 0     \n","209 | model.encoder.final_layer_norm                                      | T5LayerNorm                | 768   \n","210 | model.encoder.dropout                                               | Dropout                    | 0     \n","211 | model.decoder                                                       | T5Stack                    | 137 M \n","212 | model.decoder.block                                                 | ModuleList                 | 113 M \n","213 | model.decoder.block.0                                               | T5Block                    | 9 M   \n","214 | model.decoder.block.0.layer                                         | ModuleList                 | 9 M   \n","215 | model.decoder.block.0.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","216 | model.decoder.block.0.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","217 | model.decoder.block.0.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","218 | model.decoder.block.0.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","219 | model.decoder.block.0.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","220 | model.decoder.block.0.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","221 | model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias | Embedding                  | 384   \n","222 | model.decoder.block.0.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","223 | model.decoder.block.0.layer.0.dropout                               | Dropout                    | 0     \n","224 | model.decoder.block.0.layer.1                                       | T5LayerCrossAttention      | 2 M   \n","225 | model.decoder.block.0.layer.1.EncDecAttention                       | T5Attention                | 2 M   \n","226 | model.decoder.block.0.layer.1.EncDecAttention.q                     | Linear                     | 589 K \n","227 | model.decoder.block.0.layer.1.EncDecAttention.k                     | Linear                     | 589 K \n","228 | model.decoder.block.0.layer.1.EncDecAttention.v                     | Linear                     | 589 K \n","229 | model.decoder.block.0.layer.1.EncDecAttention.o                     | Linear                     | 589 K \n","230 | model.decoder.block.0.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","231 | model.decoder.block.0.layer.1.dropout                               | Dropout                    | 0     \n","232 | model.decoder.block.0.layer.2                                       | T5LayerFF                  | 4 M   \n","233 | model.decoder.block.0.layer.2.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","234 | model.decoder.block.0.layer.2.DenseReluDense.wi                     | Linear                     | 2 M   \n","235 | model.decoder.block.0.layer.2.DenseReluDense.wo                     | Linear                     | 2 M   \n","236 | model.decoder.block.0.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","237 | model.decoder.block.0.layer.2.layer_norm                            | T5LayerNorm                | 768   \n","238 | model.decoder.block.0.layer.2.dropout                               | Dropout                    | 0     \n","239 | model.decoder.block.1                                               | T5Block                    | 9 M   \n","240 | model.decoder.block.1.layer                                         | ModuleList                 | 9 M   \n","241 | model.decoder.block.1.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","242 | model.decoder.block.1.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","243 | model.decoder.block.1.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","244 | model.decoder.block.1.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","245 | model.decoder.block.1.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","246 | model.decoder.block.1.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","247 | model.decoder.block.1.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","248 | model.decoder.block.1.layer.0.dropout                               | Dropout                    | 0     \n","249 | model.decoder.block.1.layer.1                                       | T5LayerCrossAttention      | 2 M   \n","250 | model.decoder.block.1.layer.1.EncDecAttention                       | T5Attention                | 2 M   \n","251 | model.decoder.block.1.layer.1.EncDecAttention.q                     | Linear                     | 589 K \n","252 | model.decoder.block.1.layer.1.EncDecAttention.k                     | Linear                     | 589 K \n","253 | model.decoder.block.1.layer.1.EncDecAttention.v                     | Linear                     | 589 K \n","254 | model.decoder.block.1.layer.1.EncDecAttention.o                     | Linear                     | 589 K \n","255 | model.decoder.block.1.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","256 | model.decoder.block.1.layer.1.dropout                               | Dropout                    | 0     \n","257 | model.decoder.block.1.layer.2                                       | T5LayerFF                  | 4 M   \n","258 | model.decoder.block.1.layer.2.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","259 | model.decoder.block.1.layer.2.DenseReluDense.wi                     | Linear                     | 2 M   \n","260 | model.decoder.block.1.layer.2.DenseReluDense.wo                     | Linear                     | 2 M   \n","261 | model.decoder.block.1.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","262 | model.decoder.block.1.layer.2.layer_norm                            | T5LayerNorm                | 768   \n","263 | model.decoder.block.1.layer.2.dropout                               | Dropout                    | 0     \n","264 | model.decoder.block.2                                               | T5Block                    | 9 M   \n","265 | model.decoder.block.2.layer                                         | ModuleList                 | 9 M   \n","266 | model.decoder.block.2.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","267 | model.decoder.block.2.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","268 | model.decoder.block.2.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","269 | model.decoder.block.2.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","270 | model.decoder.block.2.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","271 | model.decoder.block.2.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","272 | model.decoder.block.2.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","273 | model.decoder.block.2.layer.0.dropout                               | Dropout                    | 0     \n","274 | model.decoder.block.2.layer.1                                       | T5LayerCrossAttention      | 2 M   \n","275 | model.decoder.block.2.layer.1.EncDecAttention                       | T5Attention                | 2 M   \n","276 | model.decoder.block.2.layer.1.EncDecAttention.q                     | Linear                     | 589 K \n","277 | model.decoder.block.2.layer.1.EncDecAttention.k                     | Linear                     | 589 K \n","278 | model.decoder.block.2.layer.1.EncDecAttention.v                     | Linear                     | 589 K \n","279 | model.decoder.block.2.layer.1.EncDecAttention.o                     | Linear                     | 589 K \n","280 | model.decoder.block.2.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","281 | model.decoder.block.2.layer.1.dropout                               | Dropout                    | 0     \n","282 | model.decoder.block.2.layer.2                                       | T5LayerFF                  | 4 M   \n","283 | model.decoder.block.2.layer.2.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","284 | model.decoder.block.2.layer.2.DenseReluDense.wi                     | Linear                     | 2 M   \n","285 | model.decoder.block.2.layer.2.DenseReluDense.wo                     | Linear                     | 2 M   \n","286 | model.decoder.block.2.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","287 | model.decoder.block.2.layer.2.layer_norm                            | T5LayerNorm                | 768   \n","288 | model.decoder.block.2.layer.2.dropout                               | Dropout                    | 0     \n","289 | model.decoder.block.3                                               | T5Block                    | 9 M   \n","290 | model.decoder.block.3.layer                                         | ModuleList                 | 9 M   \n","291 | model.decoder.block.3.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","292 | model.decoder.block.3.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","293 | model.decoder.block.3.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","294 | model.decoder.block.3.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","295 | model.decoder.block.3.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","296 | model.decoder.block.3.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","297 | model.decoder.block.3.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","298 | model.decoder.block.3.layer.0.dropout                               | Dropout                    | 0     \n","299 | model.decoder.block.3.layer.1                                       | T5LayerCrossAttention      | 2 M   \n","300 | model.decoder.block.3.layer.1.EncDecAttention                       | T5Attention                | 2 M   \n","301 | model.decoder.block.3.layer.1.EncDecAttention.q                     | Linear                     | 589 K \n","302 | model.decoder.block.3.layer.1.EncDecAttention.k                     | Linear                     | 589 K \n","303 | model.decoder.block.3.layer.1.EncDecAttention.v                     | Linear                     | 589 K \n","304 | model.decoder.block.3.layer.1.EncDecAttention.o                     | Linear                     | 589 K \n","305 | model.decoder.block.3.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","306 | model.decoder.block.3.layer.1.dropout                               | Dropout                    | 0     \n","307 | model.decoder.block.3.layer.2                                       | T5LayerFF                  | 4 M   \n","308 | model.decoder.block.3.layer.2.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","309 | model.decoder.block.3.layer.2.DenseReluDense.wi                     | Linear                     | 2 M   \n","310 | model.decoder.block.3.layer.2.DenseReluDense.wo                     | Linear                     | 2 M   \n","311 | model.decoder.block.3.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","312 | model.decoder.block.3.layer.2.layer_norm                            | T5LayerNorm                | 768   \n","313 | model.decoder.block.3.layer.2.dropout                               | Dropout                    | 0     \n","314 | model.decoder.block.4                                               | T5Block                    | 9 M   \n","315 | model.decoder.block.4.layer                                         | ModuleList                 | 9 M   \n","316 | model.decoder.block.4.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","317 | model.decoder.block.4.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","318 | model.decoder.block.4.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","319 | model.decoder.block.4.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","320 | model.decoder.block.4.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","321 | model.decoder.block.4.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","322 | model.decoder.block.4.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","323 | model.decoder.block.4.layer.0.dropout                               | Dropout                    | 0     \n","324 | model.decoder.block.4.layer.1                                       | T5LayerCrossAttention      | 2 M   \n","325 | model.decoder.block.4.layer.1.EncDecAttention                       | T5Attention                | 2 M   \n","326 | model.decoder.block.4.layer.1.EncDecAttention.q                     | Linear                     | 589 K \n","327 | model.decoder.block.4.layer.1.EncDecAttention.k                     | Linear                     | 589 K \n","328 | model.decoder.block.4.layer.1.EncDecAttention.v                     | Linear                     | 589 K \n","329 | model.decoder.block.4.layer.1.EncDecAttention.o                     | Linear                     | 589 K \n","330 | model.decoder.block.4.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","331 | model.decoder.block.4.layer.1.dropout                               | Dropout                    | 0     \n","332 | model.decoder.block.4.layer.2                                       | T5LayerFF                  | 4 M   \n","333 | model.decoder.block.4.layer.2.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","334 | model.decoder.block.4.layer.2.DenseReluDense.wi                     | Linear                     | 2 M   \n","335 | model.decoder.block.4.layer.2.DenseReluDense.wo                     | Linear                     | 2 M   \n","336 | model.decoder.block.4.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","337 | model.decoder.block.4.layer.2.layer_norm                            | T5LayerNorm                | 768   \n","338 | model.decoder.block.4.layer.2.dropout                               | Dropout                    | 0     \n","339 | model.decoder.block.5                                               | T5Block                    | 9 M   \n","340 | model.decoder.block.5.layer                                         | ModuleList                 | 9 M   \n","341 | model.decoder.block.5.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","342 | model.decoder.block.5.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","343 | model.decoder.block.5.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","344 | model.decoder.block.5.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","345 | model.decoder.block.5.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","346 | model.decoder.block.5.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","347 | model.decoder.block.5.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","348 | model.decoder.block.5.layer.0.dropout                               | Dropout                    | 0     \n","349 | model.decoder.block.5.layer.1                                       | T5LayerCrossAttention      | 2 M   \n","350 | model.decoder.block.5.layer.1.EncDecAttention                       | T5Attention                | 2 M   \n","351 | model.decoder.block.5.layer.1.EncDecAttention.q                     | Linear                     | 589 K \n","352 | model.decoder.block.5.layer.1.EncDecAttention.k                     | Linear                     | 589 K \n","353 | model.decoder.block.5.layer.1.EncDecAttention.v                     | Linear                     | 589 K \n","354 | model.decoder.block.5.layer.1.EncDecAttention.o                     | Linear                     | 589 K \n","355 | model.decoder.block.5.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","356 | model.decoder.block.5.layer.1.dropout                               | Dropout                    | 0     \n","357 | model.decoder.block.5.layer.2                                       | T5LayerFF                  | 4 M   \n","358 | model.decoder.block.5.layer.2.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","359 | model.decoder.block.5.layer.2.DenseReluDense.wi                     | Linear                     | 2 M   \n","360 | model.decoder.block.5.layer.2.DenseReluDense.wo                     | Linear                     | 2 M   \n","361 | model.decoder.block.5.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","362 | model.decoder.block.5.layer.2.layer_norm                            | T5LayerNorm                | 768   \n","363 | model.decoder.block.5.layer.2.dropout                               | Dropout                    | 0     \n","364 | model.decoder.block.6                                               | T5Block                    | 9 M   \n","365 | model.decoder.block.6.layer                                         | ModuleList                 | 9 M   \n","366 | model.decoder.block.6.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","367 | model.decoder.block.6.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","368 | model.decoder.block.6.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","369 | model.decoder.block.6.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","370 | model.decoder.block.6.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","371 | model.decoder.block.6.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","372 | model.decoder.block.6.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","373 | model.decoder.block.6.layer.0.dropout                               | Dropout                    | 0     \n","374 | model.decoder.block.6.layer.1                                       | T5LayerCrossAttention      | 2 M   \n","375 | model.decoder.block.6.layer.1.EncDecAttention                       | T5Attention                | 2 M   \n","376 | model.decoder.block.6.layer.1.EncDecAttention.q                     | Linear                     | 589 K \n","377 | model.decoder.block.6.layer.1.EncDecAttention.k                     | Linear                     | 589 K \n","378 | model.decoder.block.6.layer.1.EncDecAttention.v                     | Linear                     | 589 K \n","379 | model.decoder.block.6.layer.1.EncDecAttention.o                     | Linear                     | 589 K \n","380 | model.decoder.block.6.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","381 | model.decoder.block.6.layer.1.dropout                               | Dropout                    | 0     \n","382 | model.decoder.block.6.layer.2                                       | T5LayerFF                  | 4 M   \n","383 | model.decoder.block.6.layer.2.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","384 | model.decoder.block.6.layer.2.DenseReluDense.wi                     | Linear                     | 2 M   \n","385 | model.decoder.block.6.layer.2.DenseReluDense.wo                     | Linear                     | 2 M   \n","386 | model.decoder.block.6.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","387 | model.decoder.block.6.layer.2.layer_norm                            | T5LayerNorm                | 768   \n","388 | model.decoder.block.6.layer.2.dropout                               | Dropout                    | 0     \n","389 | model.decoder.block.7                                               | T5Block                    | 9 M   \n","390 | model.decoder.block.7.layer                                         | ModuleList                 | 9 M   \n","391 | model.decoder.block.7.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","392 | model.decoder.block.7.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","393 | model.decoder.block.7.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","394 | model.decoder.block.7.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","395 | model.decoder.block.7.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","396 | model.decoder.block.7.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","397 | model.decoder.block.7.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","398 | model.decoder.block.7.layer.0.dropout                               | Dropout                    | 0     \n","399 | model.decoder.block.7.layer.1                                       | T5LayerCrossAttention      | 2 M   \n","400 | model.decoder.block.7.layer.1.EncDecAttention                       | T5Attention                | 2 M   \n","401 | model.decoder.block.7.layer.1.EncDecAttention.q                     | Linear                     | 589 K \n","402 | model.decoder.block.7.layer.1.EncDecAttention.k                     | Linear                     | 589 K \n","403 | model.decoder.block.7.layer.1.EncDecAttention.v                     | Linear                     | 589 K \n","404 | model.decoder.block.7.layer.1.EncDecAttention.o                     | Linear                     | 589 K \n","405 | model.decoder.block.7.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","406 | model.decoder.block.7.layer.1.dropout                               | Dropout                    | 0     \n","407 | model.decoder.block.7.layer.2                                       | T5LayerFF                  | 4 M   \n","408 | model.decoder.block.7.layer.2.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","409 | model.decoder.block.7.layer.2.DenseReluDense.wi                     | Linear                     | 2 M   \n","410 | model.decoder.block.7.layer.2.DenseReluDense.wo                     | Linear                     | 2 M   \n","411 | model.decoder.block.7.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","412 | model.decoder.block.7.layer.2.layer_norm                            | T5LayerNorm                | 768   \n","413 | model.decoder.block.7.layer.2.dropout                               | Dropout                    | 0     \n","414 | model.decoder.block.8                                               | T5Block                    | 9 M   \n","415 | model.decoder.block.8.layer                                         | ModuleList                 | 9 M   \n","416 | model.decoder.block.8.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","417 | model.decoder.block.8.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","418 | model.decoder.block.8.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","419 | model.decoder.block.8.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","420 | model.decoder.block.8.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","421 | model.decoder.block.8.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","422 | model.decoder.block.8.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","423 | model.decoder.block.8.layer.0.dropout                               | Dropout                    | 0     \n","424 | model.decoder.block.8.layer.1                                       | T5LayerCrossAttention      | 2 M   \n","425 | model.decoder.block.8.layer.1.EncDecAttention                       | T5Attention                | 2 M   \n","426 | model.decoder.block.8.layer.1.EncDecAttention.q                     | Linear                     | 589 K \n","427 | model.decoder.block.8.layer.1.EncDecAttention.k                     | Linear                     | 589 K \n","428 | model.decoder.block.8.layer.1.EncDecAttention.v                     | Linear                     | 589 K \n","429 | model.decoder.block.8.layer.1.EncDecAttention.o                     | Linear                     | 589 K \n","430 | model.decoder.block.8.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","431 | model.decoder.block.8.layer.1.dropout                               | Dropout                    | 0     \n","432 | model.decoder.block.8.layer.2                                       | T5LayerFF                  | 4 M   \n","433 | model.decoder.block.8.layer.2.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","434 | model.decoder.block.8.layer.2.DenseReluDense.wi                     | Linear                     | 2 M   \n","435 | model.decoder.block.8.layer.2.DenseReluDense.wo                     | Linear                     | 2 M   \n","436 | model.decoder.block.8.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","437 | model.decoder.block.8.layer.2.layer_norm                            | T5LayerNorm                | 768   \n","438 | model.decoder.block.8.layer.2.dropout                               | Dropout                    | 0     \n","439 | model.decoder.block.9                                               | T5Block                    | 9 M   \n","440 | model.decoder.block.9.layer                                         | ModuleList                 | 9 M   \n","441 | model.decoder.block.9.layer.0                                       | T5LayerSelfAttention       | 2 M   \n","442 | model.decoder.block.9.layer.0.SelfAttention                         | T5Attention                | 2 M   \n","443 | model.decoder.block.9.layer.0.SelfAttention.q                       | Linear                     | 589 K \n","444 | model.decoder.block.9.layer.0.SelfAttention.k                       | Linear                     | 589 K \n","445 | model.decoder.block.9.layer.0.SelfAttention.v                       | Linear                     | 589 K \n","446 | model.decoder.block.9.layer.0.SelfAttention.o                       | Linear                     | 589 K \n","447 | model.decoder.block.9.layer.0.layer_norm                            | T5LayerNorm                | 768   \n","448 | model.decoder.block.9.layer.0.dropout                               | Dropout                    | 0     \n","449 | model.decoder.block.9.layer.1                                       | T5LayerCrossAttention      | 2 M   \n","450 | model.decoder.block.9.layer.1.EncDecAttention                       | T5Attention                | 2 M   \n","451 | model.decoder.block.9.layer.1.EncDecAttention.q                     | Linear                     | 589 K \n","452 | model.decoder.block.9.layer.1.EncDecAttention.k                     | Linear                     | 589 K \n","453 | model.decoder.block.9.layer.1.EncDecAttention.v                     | Linear                     | 589 K \n","454 | model.decoder.block.9.layer.1.EncDecAttention.o                     | Linear                     | 589 K \n","455 | model.decoder.block.9.layer.1.layer_norm                            | T5LayerNorm                | 768   \n","456 | model.decoder.block.9.layer.1.dropout                               | Dropout                    | 0     \n","457 | model.decoder.block.9.layer.2                                       | T5LayerFF                  | 4 M   \n","458 | model.decoder.block.9.layer.2.DenseReluDense                        | T5DenseReluDense           | 4 M   \n","459 | model.decoder.block.9.layer.2.DenseReluDense.wi                     | Linear                     | 2 M   \n","460 | model.decoder.block.9.layer.2.DenseReluDense.wo                     | Linear                     | 2 M   \n","461 | model.decoder.block.9.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","462 | model.decoder.block.9.layer.2.layer_norm                            | T5LayerNorm                | 768   \n","463 | model.decoder.block.9.layer.2.dropout                               | Dropout                    | 0     \n","464 | model.decoder.block.10                                              | T5Block                    | 9 M   \n","465 | model.decoder.block.10.layer                                        | ModuleList                 | 9 M   \n","466 | model.decoder.block.10.layer.0                                      | T5LayerSelfAttention       | 2 M   \n","467 | model.decoder.block.10.layer.0.SelfAttention                        | T5Attention                | 2 M   \n","468 | model.decoder.block.10.layer.0.SelfAttention.q                      | Linear                     | 589 K \n","469 | model.decoder.block.10.layer.0.SelfAttention.k                      | Linear                     | 589 K \n","470 | model.decoder.block.10.layer.0.SelfAttention.v                      | Linear                     | 589 K \n","471 | model.decoder.block.10.layer.0.SelfAttention.o                      | Linear                     | 589 K \n","472 | model.decoder.block.10.layer.0.layer_norm                           | T5LayerNorm                | 768   \n","473 | model.decoder.block.10.layer.0.dropout                              | Dropout                    | 0     \n","474 | model.decoder.block.10.layer.1                                      | T5LayerCrossAttention      | 2 M   \n","475 | model.decoder.block.10.layer.1.EncDecAttention                      | T5Attention                | 2 M   \n","476 | model.decoder.block.10.layer.1.EncDecAttention.q                    | Linear                     | 589 K \n","477 | model.decoder.block.10.layer.1.EncDecAttention.k                    | Linear                     | 589 K \n","478 | model.decoder.block.10.layer.1.EncDecAttention.v                    | Linear                     | 589 K \n","479 | model.decoder.block.10.layer.1.EncDecAttention.o                    | Linear                     | 589 K \n","480 | model.decoder.block.10.layer.1.layer_norm                           | T5LayerNorm                | 768   \n","481 | model.decoder.block.10.layer.1.dropout                              | Dropout                    | 0     \n","482 | model.decoder.block.10.layer.2                                      | T5LayerFF                  | 4 M   \n","483 | model.decoder.block.10.layer.2.DenseReluDense                       | T5DenseReluDense           | 4 M   \n","484 | model.decoder.block.10.layer.2.DenseReluDense.wi                    | Linear                     | 2 M   \n","485 | model.decoder.block.10.layer.2.DenseReluDense.wo                    | Linear                     | 2 M   \n","486 | model.decoder.block.10.layer.2.DenseReluDense.dropout               | Dropout                    | 0     \n","487 | model.decoder.block.10.layer.2.layer_norm                           | T5LayerNorm                | 768   \n","488 | model.decoder.block.10.layer.2.dropout                              | Dropout                    | 0     \n","489 | model.decoder.block.11                                              | T5Block                    | 9 M   \n","490 | model.decoder.block.11.layer                                        | ModuleList                 | 9 M   \n","491 | model.decoder.block.11.layer.0                                      | T5LayerSelfAttention       | 2 M   \n","492 | model.decoder.block.11.layer.0.SelfAttention                        | T5Attention                | 2 M   \n","493 | model.decoder.block.11.layer.0.SelfAttention.q                      | Linear                     | 589 K \n","494 | model.decoder.block.11.layer.0.SelfAttention.k                      | Linear                     | 589 K \n","495 | model.decoder.block.11.layer.0.SelfAttention.v                      | Linear                     | 589 K \n","496 | model.decoder.block.11.layer.0.SelfAttention.o                      | Linear                     | 589 K \n","497 | model.decoder.block.11.layer.0.layer_norm                           | T5LayerNorm                | 768   \n","498 | model.decoder.block.11.layer.0.dropout                              | Dropout                    | 0     \n","499 | model.decoder.block.11.layer.1                                      | T5LayerCrossAttention      | 2 M   \n","500 | model.decoder.block.11.layer.1.EncDecAttention                      | T5Attention                | 2 M   \n","501 | model.decoder.block.11.layer.1.EncDecAttention.q                    | Linear                     | 589 K \n","502 | model.decoder.block.11.layer.1.EncDecAttention.k                    | Linear                     | 589 K \n","503 | model.decoder.block.11.layer.1.EncDecAttention.v                    | Linear                     | 589 K \n","504 | model.decoder.block.11.layer.1.EncDecAttention.o                    | Linear                     | 589 K \n","505 | model.decoder.block.11.layer.1.layer_norm                           | T5LayerNorm                | 768   \n","506 | model.decoder.block.11.layer.1.dropout                              | Dropout                    | 0     \n","507 | model.decoder.block.11.layer.2                                      | T5LayerFF                  | 4 M   \n","508 | model.decoder.block.11.layer.2.DenseReluDense                       | T5DenseReluDense           | 4 M   \n","509 | model.decoder.block.11.layer.2.DenseReluDense.wi                    | Linear                     | 2 M   \n","510 | model.decoder.block.11.layer.2.DenseReluDense.wo                    | Linear                     | 2 M   \n","511 | model.decoder.block.11.layer.2.DenseReluDense.dropout               | Dropout                    | 0     \n","512 | model.decoder.block.11.layer.2.layer_norm                           | T5LayerNorm                | 768   \n","513 | model.decoder.block.11.layer.2.dropout                              | Dropout                    | 0     \n","514 | model.decoder.final_layer_norm                                      | T5LayerNorm                | 768   \n","515 | model.decoder.dropout                                               | Dropout                    | 0     \n","516 | model.lm_head                                                       | Linear                     | 24 M  \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"786a857e9263477480cc73e97531c0d0","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fd13adec3994900b687fe097b4e84c8","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0fb57157fc643a58174283c69a2ecfb","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Validation results *****\n","INFO:__main__:avg_val_loss = tensor(nan, device='cuda:0')\n","\n","INFO:__main__:loss = tensor(nan, device='cuda:0')\n","\n","INFO:__main__:train_loss = tensor(nan, device='cuda:0')\n","\n","INFO:__main__:val_loss = tensor(nan, device='cuda:0')\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e858d7eea959464788c0b4d9cffbbdca","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Validation results *****\n","INFO:__main__:avg_train_loss = tensor(nan, device='cuda:0')\n","\n","INFO:__main__:avg_val_loss = tensor(nan, device='cuda:0')\n","\n","INFO:__main__:epoch = 0\n","\n","INFO:__main__:loss = tensor(nan, device='cuda:0')\n","\n","INFO:__main__:train_loss = tensor(nan, device='cuda:0')\n","\n","INFO:__main__:val_loss = tensor(nan, device='cuda:0')\n","\n"]},{"output_type":"stream","name":"stdout","text":["training finished\n","Saving model\n","Model saved\n"]}]},{"cell_type":"code","source":["pl.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"B1UueUs5MHOy","executionInfo":{"status":"ok","timestamp":1639640509633,"user_tz":-420,"elapsed":292,"user":{"displayName":"Quang Vu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13671972817026223059"}},"outputId":"69997b86-cf67-4136-9db0-ab20727e2754"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'0.7.5'"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# !ls /content/drive/MyDrive/VIN_NLP/ThanhQuang_NLP/t5_paraphrase\n","!ls /content/drive/Shareddrives/hoa.lenghiem/ThanhQuang_NLP/save_check_point"],"metadata":{"id":"dQ41rJ3PLfJw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639737829422,"user_tz":-420,"elapsed":351,"user":{"displayName":"Nghiem Hoa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02320684392395045478"}},"outputId":"b3824f51-e85d-4a9c-d5d2-cd3ee0e009c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'checkpointepoch=0.ckpt'   config.json\n","'checkpointepoch=1.ckpt'   pytorch_model.bin\n"]}]},{"cell_type":"markdown","metadata":{"id":"OeHmedYU95P5"},"source":["# **Start testing**"]},{"cell_type":"code","source":[""],"metadata":{"id":"HAm8bYw1u5B0"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MlvJHBTJ93_n","colab":{"base_uri":"https://localhost:8080/","height":148,"referenced_widgets":["e0cf1a2139b94830a944fc95899d5734","631557f009c2470ea405d212e9659640","72cc0f753e37411da87b96e843a1a2cc","f8dea0aa13cb46479d2c86cde21835f0","28efbe0f4742469bb2eced8909c0a34f","be2846b4fe9446c792d365b2b2913b24","0266fd4013ae4ccd8facc3e000367d4e","4cc60e47775c4da9b7c61f98cb8327f2","77db5b5380604e18b993caef9917cdd7","a54cca7b7909446e9aae31275c0c6a30","7ca697f1060f4780b49073b5d6fecc94","87cc0c1c8f824b5a88dbe90219c2cc50","2831664a75eb4bd28813b0386b584c51","d9dcb1f9b65a4cb195085de40053f128","41339b75bbb342b28f4eb9b2f5e89cfb","5248a530729f42739aebb473991cecbe","10600c6cea4a4ff9823393de89aabba4","53df41c9a0844e019abe3d65f6180307","bdbaadf61df0499391fe163b5ae1db1c","00dcfe16c6a445479ac63e1ec1faee28","c358f21aa15b4712adf70641aab76d6c","a22b08194d9b47b2a6c7143eb3f9255b","f5b1c9156a9f421b8540de602854e7a0","e28fc364069741a2aafe0e345d1b7b6e","00479bdd78784ec989ca285557fa3e2d","9f759653f8d644528402e2e7a230796a","f1d681f96ea74dcd9f7227a0fc485c0f","d071c388224c42969d66d88287eb944e","e7ef85c5af0242bcbc25d1869ee126f8","7d2994b929f5458c9fd1ad5bdf76b102","88a4727a098243fa8eab104babb4930c","75ddab400c9b4ecb87a7c7311aee5079","dc9a96835a3d4caabc95ac395938c4bf"]},"executionInfo":{"status":"ok","timestamp":1639738920967,"user_tz":-420,"elapsed":11024,"user":{"displayName":"Nghiem Hoa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02320684392395045478"}},"outputId":"847ce140-f6a3-421d-db04-a3267a3d638a"},"source":["import torch\n","from transformers import T5ForConditionalGeneration\n","\n","def set_seed(seed):\n","  torch.manual_seed(seed)\n","#  if torch.cuda.is_available():\n","\n","#   torch.cuda.manual_seed_all(seed)\n","\n","set_seed(42)\n","\n","best_model_path = \"save_check_point\"\n","model = T5ForConditionalGeneration.from_pretrained(best_model_path)\n","tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base')\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print (\"device \",device)\n","model = model.to(device)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0cf1a2139b94830a944fc95899d5734","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/874k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87cc0c1c8f824b5a88dbe90219c2cc50","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f5b1c9156a9f421b8540de602854e7a0","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/557 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"stream","name":"stdout","text":["device  cpu\n"]}]},{"cell_type":"code","source":["!pip install pyvi\n","\n","!pip install https://gitlab.com/trungtv/vi_spacy/-/raw/master/vi_core_news_lg/dist/vi_core_news_lg-0.0.1.tar.gz\n","\n","\n","'''\n","\n","tokenization code\n","\n","'''\n","\n","import spacy\n","\n","spacy_vi = spacy.load('vi_core_news_lg')\n","\n","\n","\n","def tokenize_vi(text):\n","\n","    \"\"\"\n","\n","    Tokenizes Vietnamese text from a string into a list of strings (tokens)\n","\n","    \"\"\"\n","\n","    return [tok.text for tok in spacy_vi.tokenizer(text)]"],"metadata":{"id":"n7w7aEE8XtGR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639739017748,"user_tz":-420,"elapsed":69845,"user":{"displayName":"Nghiem Hoa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02320684392395045478"}},"outputId":"4245b524-2e90-4f2b-8198-d9e36163bda9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyvi\n","  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n","\u001b[K     |████████████████████████████████| 8.5 MB 4.5 MB/s \n","\u001b[?25hCollecting sklearn-crfsuite\n","  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (1.0.1)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (3.0.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n","Collecting python-crfsuite>=0.8.3\n","  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n","\u001b[K     |████████████████████████████████| 743 kB 29.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.62.3)\n","Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n","Successfully installed python-crfsuite-0.9.7 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n","Collecting https://gitlab.com/trungtv/vi_spacy/-/raw/master/vi_core_news_lg/dist/vi_core_news_lg-0.0.1.tar.gz\n","  Downloading https://gitlab.com/trungtv/vi_spacy/-/raw/master/vi_core_news_lg/dist/vi_core_news_lg-0.0.1.tar.gz (254.5 MB)\n","\u001b[K     |████████████████████████████████| 254.5 MB 35 kB/s \n","\u001b[?25hCollecting spacy<3.1.0,>=3.0.5\n","  Downloading spacy-3.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n","\u001b[K     |████████████████████████████████| 6.3 MB 4.1 MB/s \n","\u001b[?25hCollecting thinc<8.1.0,>=8.0.3\n","  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n","\u001b[K     |████████████████████████████████| 628 kB 49.4 MB/s \n","\u001b[?25hCollecting pathy>=0.3.5\n","  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.0 MB/s \n","\u001b[?25hCollecting srsly<3.0.0,>=2.4.1\n","  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n","\u001b[K     |████████████████████████████████| 451 kB 50.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (4.62.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (1.19.5)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (0.8.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (1.0.6)\n","Collecting catalogue<2.1.0,>=2.0.4\n","  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (3.10.0.2)\n","Collecting spacy-legacy<3.1.0,>=3.0.5\n","  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (2.11.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (21.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (57.4.0)\n","Collecting typer<0.4.0,>=0.3.0\n","  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (0.4.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (2.23.0)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 54.3 MB/s \n","\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (2.0.6)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (3.0.6)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (5.2.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (2021.10.8)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.5->vi-core-news-lg==0.0.1) (2.0.1)\n","Building wheels for collected packages: vi-core-news-lg\n","  Building wheel for vi-core-news-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vi-core-news-lg: filename=vi_core_news_lg-0.0.1-py3-none-any.whl size=254513617 sha256=439a5278b1497fbc7be049a6b5ef7c7d4255d1e9ebacb7ebd1cab95069292ff2\n","  Stored in directory: /root/.cache/pip/wheels/e4/d9/90/dcbb25186a2c3335b17bc675f8dddcb43ecdfa4b400e8c91b0\n","Successfully built vi-core-news-lg\n","Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-legacy, pathy, spacy, vi-core-news-lg\n","  Attempting uninstall: catalogue\n","    Found existing installation: catalogue 1.0.0\n","    Uninstalling catalogue-1.0.0:\n","      Successfully uninstalled catalogue-1.0.0\n","  Attempting uninstall: srsly\n","    Found existing installation: srsly 1.0.5\n","    Uninstalling srsly-1.0.5:\n","      Successfully uninstalled srsly-1.0.5\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed catalogue-2.0.6 pathy-0.6.1 pydantic-1.8.2 spacy-3.0.7 spacy-legacy-3.0.8 srsly-2.4.2 thinc-8.0.13 typer-0.3.2 vi-core-news-lg-0.0.1\n"]}]},{"cell_type":"code","metadata":{"id":"iyARaz5z_OJM","colab":{"base_uri":"https://localhost:8080/","height":765},"executionInfo":{"status":"error","timestamp":1639739021547,"user_tz":-420,"elapsed":667,"user":{"displayName":"Nghiem Hoa","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02320684392395045478"}},"outputId":"f0f14ab6-a93c-44a9-d07a-ffc94af61f6d"},"source":["sentence_1 = \"Để bán được hàng thành công , trước tiên bạn phải yêu quý công việc và hết lòng vì nó\"\n","sentence_2 = \"Wikipedia was launched on January 15, 2001, and was created by Jimmy Wales and Larry Sanger.\"\n","sentence_3 = \"Điều này cho phép bạn lựa chọn những công việc cần phải hoàn thành trong ngày hôm đó và loại bỏ các công việc có thể hoàn thành vào các ngày khác\"\n","sentence_4 = \"Điều này cho phép bạn lựa chọn những công việc cần phải hoàn thành trong ngày hôm đó và loại bỏ các công việc có thể hoàn thành vào các ngày khác\"\n","sentence_5 = \"Which course should I take to get started in data science?\"\n","\n","# model = model.to(device)\n","sentence = ' '.join(tokenize_vi(sentence_3))\n","\n","# sentence = sentence_1\n","\n","\n","# text = '<s> ' + sentence + ' </s>'\n","text = sentence\n","\n","# print(text)\n","# features = tokenizer.encode(text)\n","# print(\"we\", features)\n","# phobert_model = AutoModel('vinio/phobert-base')\n","# print(phobert_model.decode(features))\n","# tokenizer = PhobertTokenizer.from_pretrained('vinai/phobert-base')\n","max_len = 256\n","\n","encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n","input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n","\n","# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n","beam_outputs = model.generate(\n","    input_ids=input_ids, attention_mask=attention_masks,\n","    do_sample=True,\n","    max_length=256,\n","    top_k=120,\n","    top_p=0.98,\n","    # early_stopping=False,\n","    num_return_sequences=1\n",")\n","\n","print (\"\\nOriginal sentence: \")\n","print (sentence)\n","print (\"\\n\")\n","print (\"Paraphrased sentences: \")\n","final_outputs =[]\n","for beam_output in beam_outputs:\n","    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n","    print(sent)\n","    if sent.lower() != text.lower() and sent not in final_outputs:\n","        print(sent)\n","        final_outputs.append(sent)  \n","\n","for i, final_output in enumerate(final_outputs):\n","    print(\"{}: {}\".format(i, final_output))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-f73594c1472a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.98\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# early_stopping=False,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m             )\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1582\u001b[0m             \u001b[0;31m# sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1584\u001b[0;31m             \u001b[0mnext_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m             \u001b[0;31m# finished sentences should have their next token be a padding token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: invalid multinomial distribution (encountering probability entry < 0)"]}]},{"cell_type":"code","source":["for beam_output in beam_outputs:\n","    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n","    print(sent)\n","    if sent.lower() != text.lower() and sent not in final_outputs:\n","        print(sent)\n","        final_outputs.append(sent)  \n","\n","for i, final_output in enumerate(final_outputs):\n","    print(\"{}: {}\".format(i, final_output))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"zVOtn62-5PI4","outputId":"1171abb1-3ed4-414c-e3bc-36877020c2f9","executionInfo":{"status":"error","timestamp":1639631309020,"user_tz":-420,"elapsed":8,"user":{"displayName":"Quang Vu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11086209231479786423"}}},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-0d2756486e1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbeam_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbeam_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'beam_outputs' is not defined"]}]},{"cell_type":"code","source":["!cp /content/t5_paraphrase "],"metadata":{"id":"bXRfvK1sZNPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MMFfZPRebQZQ"},"source":["|# !pip install transformers\n","# !pip install sentencepiece"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NkqlI76PIHYQ"},"source":["import torch\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MZ4ZsE3ZbDiJ"},"source":["def set_seed(seed):\n","  torch.manual_seed(seed)\n","  if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","\n","set_seed(42)\n","\n","best_model_path = \"drive/My Drive/Inabia NLP Models/T5-small-fine-tuned-2 epoch (PAWS)/t5_paraphrase\"\n","model = T5ForConditionalGeneration.from_pretrained(best_model_path)\n","tokenizer = PhobertTokenizer.from_pretrained('vinai/phobert-base')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IU7HNvvxtNHj"},"source":["import tensorflow as tf\n","import tensorflow_text  # Required to run exported model.\n","\n","model = tf.saved_model.load(saved_model_path, [\"serve\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Resume training"],"metadata":{"id":"BCfotSyu5z6M"}},{"cell_type":"code","source":["dataset = ParaphraseDataset(tokenizer, '/content/drive/MyDrive/VIN_NLP/merge_pair_sentence_dataset', 'dev_label_1_pyvi_seg', 256)\n","print(\"Val dataset: \",len(dataset))\n","\n","data = dataset[61]\n","# print(tokenizer.decode(data['source_ids']))\n","# print(tokenizer.decode(data['target_ids']))\n","\n","if not os.path.exists('t5_paraphrase'):\n","    os.makedirs('t5_paraphrase')\n","\n","args_dict.update({'data_dir': '/content/drive/MyDrive/VIN_NLP/merge_pair_sentence_dataset', 'output_dir': 't5_paraphrase', 'num_train_epochs':10,'max_seq_length':256})\n","args = argparse.Namespace(**args_dict)\n","print(args_dict)\n","\n","\n","\n","checkpoint_callback = pl.callbacks.ModelCheckpoint(\n","    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",")\n","\n","train_params = dict(\n","    accumulate_grad_batches=args.gradient_accumulation_steps,\n","    gpus=args.n_gpu,\n","    max_epochs=args.num_train_epochs,\n"," #   early_stop_callback=False,\n","    precision= 16 if args.fp_16 else 32,\n","    amp_level=args.opt_level,\n","    gradient_clip_val=args.max_grad_norm,\n","    checkpoint_callback=checkpoint_callback,\n","    callbacks=[LoggingCallback()],\n","    ckpt_path = '/content/drive/MyDrive/t5_paraphrase_2/checkpointepoch=5.ckpt',\n","    resume_from_checkpoint = '/content/drive/MyDrive/t5_paraphrase_2/checkpointepoch=5.ckpt'\n","    \n",")\n","\n","def get_dataset(tokenizer, type_path, args):\n","  return ParaphraseDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)\n","\n","print (\"Initialize model\")\n","model = T5FineTuner(args)\n","\n","trainer = pl.Trainer(**train_params)\n","\n","print (\" Training model\")\n","trainer.fit(model)\n","\n","\n","print (\"training finished\")\n","\n","print (\"Saving model\")\n","model.model.save_pretrained('t5_paraphrase')\n","\n","print (\"Model saved\")\n","\n","!cp \"/content/t5_paraphrase/\" -a \"/content/drive/My Drive/\"\n","!cp \"/content/lightning_logs/\" -a \"/content/drive/My Drive/\"\n","print (\"Copied the final folder to Google Drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f99502b27dda448aa5223f9333545789","68c9bc72cc604d3ebe840054e58973e6","f8842f80304e42e38a06d799c6887bfd","6034683070654958b1c314bc35a0bda3","e6f377b5c7114290809e155918584e4b","90be3c64c57f46389a61c6e1b27f8bb6","5a46fdfae04242a6ba77795cec8b8d3d","f27cef51a7f343e0b0149dc1d24bdf9a","8cfebb4301564f84802a2eb426e17e88","0892a83ad4b841838dcd53da3d890f22","dc10396467884e328a57fe19242a884f","19b895793c6c4683bdfedb1914efc912","0ceeecbf67874b22b1ceace509e1a2f4","3ea8ac33ee14402da734d7fd2664198d","c184e10fd22b43e4aa6f1743bed4b45d","49673cef5663430e9d86a4e2d4b10a58","3a8fac70a7524b41bf161b31644a1b7d","3c6efb0f867742f7b6d6760fa4d02ae2","fe2e49fcb93b417d8a6e1e174054d268","b1d41897674d4c25b5a185c81c80a873","ceb317454a2648b58ae14d0512bd49b3","2b75986e64964fdbb776b649cae45b50","b0fd9a86ddb643bd8df34bf5b5621bbd","3074e1a81dd048fdbd0de1c4993ba1b4","d85f538f84c3459092387296f65456b5","e1d62e6db2e94bd9a09fbddc57ae0698","81fa3c59975e4d03bc5dca872680645d","610d06a66bc740b08480023c68a833eb","e0ac750f91304c3299b3a0b5fc154b06","e4e68da07f8c42ba91cbc5d714c9f617","ebddce8de78945838f9b1fd9b21ae438","a4c8df8ded614310b65979e7fad33773","d434d6c4c8f8470bada2a7cd019d5de4","6882fafe84284c16b978d8503beb598b","f8bc676b7fc94e3c88fbf2928941a398","7ff938d60fbd429789f1a07299810fca","09cffcafcbe542bda63c85300b33865c","b64b65f806be44fe91445daf5a6ab83b","e96d7182a4344e78b50759c59fb3b171","d80dec6f48954d168b2b24f3a363b1b0","0392eba8742b430a84b2738c3bd3a344","0a9476159e3547819260ac04150673b2","cec859d9d6104a6c85d65ed99da19cc7","cbe48690d65145669569a0ffc09dcb5a","c1d9829b85134135bac7c92837847036","264648e353244bba91dac38f504e8feb","15c0c26bff874486aa893df78be33362","d02edd4ef4794f7ea763e2da965e2eb8","296832c4984c4191b36a720109a3e2e7","1ebd37079d394527b9157fa740aaa01c","63d48d9878734231b6fef5a7145fa700","210af43b19a54ca0b93b7b41b05f5a11","7f79ada0d1ed4ca780dad49715070cad","6c6ee033cd2a483b9f5c9f7ae7119a8f","03e1bc97f613498ea0824c8b040d299e","5c62d16743014791ac85e8e87b2814c2","539e3a99aa7f47d7b05a4c4427570da5","33935782b2a344e8afd9fd9ba898ac1b","b571b9ac4d9a405596f184d704a452fc","fd1bb913e46c4783bcc4700c929af36b","70e3c9d1cfb0471e99eff7828831517d","38b4c9ac743443eca8ddd4dc668cc146","b0a3ca9c4a4f42159ce58f8ace137af6","7a3dd1cdf16e482db011d82f496246e9","89d832a0bc1c449a81ea0961bc465db8","8d6bbc44c2dd4d4e9ba12bef8faf58d6"]},"id":"TIEeDzwY5100","outputId":"5c9e7e75-ec2d-47c4-ea7a-dadbc4a84ac8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Val dataset:  814\n","{'data_dir': '/content/drive/MyDrive/VIN_NLP/merge_pair_sentence_dataset', 'output_dir': 't5_paraphrase', 'model_name_or_path': 't5-small', 'tokenizer_name_or_path': 'vinai/phobert-base', 'max_seq_length': 256, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'train_batch_size': 2, 'eval_batch_size': 2, 'num_train_epochs': 10, 'gradient_accumulation_steps': 16, 'n_gpu': 1, 'early_stop_callback': False, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42}\n","Initialize model\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: Checkpoint directory t5_paraphrase exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n","  warnings.warn(*args, **kwargs)\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","INFO:lightning:GPU available: True, used: True\n","INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"stream","name":"stdout","text":[" Training model\n"]},{"output_type":"stream","name":"stderr","text":["INFO:lightning:\n","    | Name                                                                | Type                       | Params\n","---------------------------------------------------------------------------------------------------------------\n","0   | model                                                               | T5ForConditionalGeneration | 60 M  \n","1   | model.shared                                                        | Embedding                  | 16 M  \n","2   | model.encoder                                                       | T5Stack                    | 35 M  \n","3   | model.encoder.block                                                 | ModuleList                 | 18 M  \n","4   | model.encoder.block.0                                               | T5Block                    | 3 M   \n","5   | model.encoder.block.0.layer                                         | ModuleList                 | 3 M   \n","6   | model.encoder.block.0.layer.0                                       | T5LayerSelfAttention       | 1 M   \n","7   | model.encoder.block.0.layer.0.SelfAttention                         | T5Attention                | 1 M   \n","8   | model.encoder.block.0.layer.0.SelfAttention.q                       | Linear                     | 262 K \n","9   | model.encoder.block.0.layer.0.SelfAttention.k                       | Linear                     | 262 K \n","10  | model.encoder.block.0.layer.0.SelfAttention.v                       | Linear                     | 262 K \n","11  | model.encoder.block.0.layer.0.SelfAttention.o                       | Linear                     | 262 K \n","12  | model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias | Embedding                  | 256   \n","13  | model.encoder.block.0.layer.0.layer_norm                            | T5LayerNorm                | 512   \n","14  | model.encoder.block.0.layer.0.dropout                               | Dropout                    | 0     \n","15  | model.encoder.block.0.layer.1                                       | T5LayerFF                  | 2 M   \n","16  | model.encoder.block.0.layer.1.DenseReluDense                        | T5DenseReluDense           | 2 M   \n","17  | model.encoder.block.0.layer.1.DenseReluDense.wi                     | Linear                     | 1 M   \n","18  | model.encoder.block.0.layer.1.DenseReluDense.wo                     | Linear                     | 1 M   \n","19  | model.encoder.block.0.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","20  | model.encoder.block.0.layer.1.layer_norm                            | T5LayerNorm                | 512   \n","21  | model.encoder.block.0.layer.1.dropout                               | Dropout                    | 0     \n","22  | model.encoder.block.1                                               | T5Block                    | 3 M   \n","23  | model.encoder.block.1.layer                                         | ModuleList                 | 3 M   \n","24  | model.encoder.block.1.layer.0                                       | T5LayerSelfAttention       | 1 M   \n","25  | model.encoder.block.1.layer.0.SelfAttention                         | T5Attention                | 1 M   \n","26  | model.encoder.block.1.layer.0.SelfAttention.q                       | Linear                     | 262 K \n","27  | model.encoder.block.1.layer.0.SelfAttention.k                       | Linear                     | 262 K \n","28  | model.encoder.block.1.layer.0.SelfAttention.v                       | Linear                     | 262 K \n","29  | model.encoder.block.1.layer.0.SelfAttention.o                       | Linear                     | 262 K \n","30  | model.encoder.block.1.layer.0.layer_norm                            | T5LayerNorm                | 512   \n","31  | model.encoder.block.1.layer.0.dropout                               | Dropout                    | 0     \n","32  | model.encoder.block.1.layer.1                                       | T5LayerFF                  | 2 M   \n","33  | model.encoder.block.1.layer.1.DenseReluDense                        | T5DenseReluDense           | 2 M   \n","34  | model.encoder.block.1.layer.1.DenseReluDense.wi                     | Linear                     | 1 M   \n","35  | model.encoder.block.1.layer.1.DenseReluDense.wo                     | Linear                     | 1 M   \n","36  | model.encoder.block.1.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","37  | model.encoder.block.1.layer.1.layer_norm                            | T5LayerNorm                | 512   \n","38  | model.encoder.block.1.layer.1.dropout                               | Dropout                    | 0     \n","39  | model.encoder.block.2                                               | T5Block                    | 3 M   \n","40  | model.encoder.block.2.layer                                         | ModuleList                 | 3 M   \n","41  | model.encoder.block.2.layer.0                                       | T5LayerSelfAttention       | 1 M   \n","42  | model.encoder.block.2.layer.0.SelfAttention                         | T5Attention                | 1 M   \n","43  | model.encoder.block.2.layer.0.SelfAttention.q                       | Linear                     | 262 K \n","44  | model.encoder.block.2.layer.0.SelfAttention.k                       | Linear                     | 262 K \n","45  | model.encoder.block.2.layer.0.SelfAttention.v                       | Linear                     | 262 K \n","46  | model.encoder.block.2.layer.0.SelfAttention.o                       | Linear                     | 262 K \n","47  | model.encoder.block.2.layer.0.layer_norm                            | T5LayerNorm                | 512   \n","48  | model.encoder.block.2.layer.0.dropout                               | Dropout                    | 0     \n","49  | model.encoder.block.2.layer.1                                       | T5LayerFF                  | 2 M   \n","50  | model.encoder.block.2.layer.1.DenseReluDense                        | T5DenseReluDense           | 2 M   \n","51  | model.encoder.block.2.layer.1.DenseReluDense.wi                     | Linear                     | 1 M   \n","52  | model.encoder.block.2.layer.1.DenseReluDense.wo                     | Linear                     | 1 M   \n","53  | model.encoder.block.2.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","54  | model.encoder.block.2.layer.1.layer_norm                            | T5LayerNorm                | 512   \n","55  | model.encoder.block.2.layer.1.dropout                               | Dropout                    | 0     \n","56  | model.encoder.block.3                                               | T5Block                    | 3 M   \n","57  | model.encoder.block.3.layer                                         | ModuleList                 | 3 M   \n","58  | model.encoder.block.3.layer.0                                       | T5LayerSelfAttention       | 1 M   \n","59  | model.encoder.block.3.layer.0.SelfAttention                         | T5Attention                | 1 M   \n","60  | model.encoder.block.3.layer.0.SelfAttention.q                       | Linear                     | 262 K \n","61  | model.encoder.block.3.layer.0.SelfAttention.k                       | Linear                     | 262 K \n","62  | model.encoder.block.3.layer.0.SelfAttention.v                       | Linear                     | 262 K \n","63  | model.encoder.block.3.layer.0.SelfAttention.o                       | Linear                     | 262 K \n","64  | model.encoder.block.3.layer.0.layer_norm                            | T5LayerNorm                | 512   \n","65  | model.encoder.block.3.layer.0.dropout                               | Dropout                    | 0     \n","66  | model.encoder.block.3.layer.1                                       | T5LayerFF                  | 2 M   \n","67  | model.encoder.block.3.layer.1.DenseReluDense                        | T5DenseReluDense           | 2 M   \n","68  | model.encoder.block.3.layer.1.DenseReluDense.wi                     | Linear                     | 1 M   \n","69  | model.encoder.block.3.layer.1.DenseReluDense.wo                     | Linear                     | 1 M   \n","70  | model.encoder.block.3.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","71  | model.encoder.block.3.layer.1.layer_norm                            | T5LayerNorm                | 512   \n","72  | model.encoder.block.3.layer.1.dropout                               | Dropout                    | 0     \n","73  | model.encoder.block.4                                               | T5Block                    | 3 M   \n","74  | model.encoder.block.4.layer                                         | ModuleList                 | 3 M   \n","75  | model.encoder.block.4.layer.0                                       | T5LayerSelfAttention       | 1 M   \n","76  | model.encoder.block.4.layer.0.SelfAttention                         | T5Attention                | 1 M   \n","77  | model.encoder.block.4.layer.0.SelfAttention.q                       | Linear                     | 262 K \n","78  | model.encoder.block.4.layer.0.SelfAttention.k                       | Linear                     | 262 K \n","79  | model.encoder.block.4.layer.0.SelfAttention.v                       | Linear                     | 262 K \n","80  | model.encoder.block.4.layer.0.SelfAttention.o                       | Linear                     | 262 K \n","81  | model.encoder.block.4.layer.0.layer_norm                            | T5LayerNorm                | 512   \n","82  | model.encoder.block.4.layer.0.dropout                               | Dropout                    | 0     \n","83  | model.encoder.block.4.layer.1                                       | T5LayerFF                  | 2 M   \n","84  | model.encoder.block.4.layer.1.DenseReluDense                        | T5DenseReluDense           | 2 M   \n","85  | model.encoder.block.4.layer.1.DenseReluDense.wi                     | Linear                     | 1 M   \n","86  | model.encoder.block.4.layer.1.DenseReluDense.wo                     | Linear                     | 1 M   \n","87  | model.encoder.block.4.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","88  | model.encoder.block.4.layer.1.layer_norm                            | T5LayerNorm                | 512   \n","89  | model.encoder.block.4.layer.1.dropout                               | Dropout                    | 0     \n","90  | model.encoder.block.5                                               | T5Block                    | 3 M   \n","91  | model.encoder.block.5.layer                                         | ModuleList                 | 3 M   \n","92  | model.encoder.block.5.layer.0                                       | T5LayerSelfAttention       | 1 M   \n","93  | model.encoder.block.5.layer.0.SelfAttention                         | T5Attention                | 1 M   \n","94  | model.encoder.block.5.layer.0.SelfAttention.q                       | Linear                     | 262 K \n","95  | model.encoder.block.5.layer.0.SelfAttention.k                       | Linear                     | 262 K \n","96  | model.encoder.block.5.layer.0.SelfAttention.v                       | Linear                     | 262 K \n","97  | model.encoder.block.5.layer.0.SelfAttention.o                       | Linear                     | 262 K \n","98  | model.encoder.block.5.layer.0.layer_norm                            | T5LayerNorm                | 512   \n","99  | model.encoder.block.5.layer.0.dropout                               | Dropout                    | 0     \n","100 | model.encoder.block.5.layer.1                                       | T5LayerFF                  | 2 M   \n","101 | model.encoder.block.5.layer.1.DenseReluDense                        | T5DenseReluDense           | 2 M   \n","102 | model.encoder.block.5.layer.1.DenseReluDense.wi                     | Linear                     | 1 M   \n","103 | model.encoder.block.5.layer.1.DenseReluDense.wo                     | Linear                     | 1 M   \n","104 | model.encoder.block.5.layer.1.DenseReluDense.dropout                | Dropout                    | 0     \n","105 | model.encoder.block.5.layer.1.layer_norm                            | T5LayerNorm                | 512   \n","106 | model.encoder.block.5.layer.1.dropout                               | Dropout                    | 0     \n","107 | model.encoder.final_layer_norm                                      | T5LayerNorm                | 512   \n","108 | model.encoder.dropout                                               | Dropout                    | 0     \n","109 | model.decoder                                                       | T5Stack                    | 41 M  \n","110 | model.decoder.block                                                 | ModuleList                 | 25 M  \n","111 | model.decoder.block.0                                               | T5Block                    | 4 M   \n","112 | model.decoder.block.0.layer                                         | ModuleList                 | 4 M   \n","113 | model.decoder.block.0.layer.0                                       | T5LayerSelfAttention       | 1 M   \n","114 | model.decoder.block.0.layer.0.SelfAttention                         | T5Attention                | 1 M   \n","115 | model.decoder.block.0.layer.0.SelfAttention.q                       | Linear                     | 262 K \n","116 | model.decoder.block.0.layer.0.SelfAttention.k                       | Linear                     | 262 K \n","117 | model.decoder.block.0.layer.0.SelfAttention.v                       | Linear                     | 262 K \n","118 | model.decoder.block.0.layer.0.SelfAttention.o                       | Linear                     | 262 K \n","119 | model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias | Embedding                  | 256   \n","120 | model.decoder.block.0.layer.0.layer_norm                            | T5LayerNorm                | 512   \n","121 | model.decoder.block.0.layer.0.dropout                               | Dropout                    | 0     \n","122 | model.decoder.block.0.layer.1                                       | T5LayerCrossAttention      | 1 M   \n","123 | model.decoder.block.0.layer.1.EncDecAttention                       | T5Attention                | 1 M   \n","124 | model.decoder.block.0.layer.1.EncDecAttention.q                     | Linear                     | 262 K \n","125 | model.decoder.block.0.layer.1.EncDecAttention.k                     | Linear                     | 262 K \n","126 | model.decoder.block.0.layer.1.EncDecAttention.v                     | Linear                     | 262 K \n","127 | model.decoder.block.0.layer.1.EncDecAttention.o                     | Linear                     | 262 K \n","128 | model.decoder.block.0.layer.1.layer_norm                            | T5LayerNorm                | 512   \n","129 | model.decoder.block.0.layer.1.dropout                               | Dropout                    | 0     \n","130 | model.decoder.block.0.layer.2                                       | T5LayerFF                  | 2 M   \n","131 | model.decoder.block.0.layer.2.DenseReluDense                        | T5DenseReluDense           | 2 M   \n","132 | model.decoder.block.0.layer.2.DenseReluDense.wi                     | Linear                     | 1 M   \n","133 | model.decoder.block.0.layer.2.DenseReluDense.wo                     | Linear                     | 1 M   \n","134 | model.decoder.block.0.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","135 | model.decoder.block.0.layer.2.layer_norm                            | T5LayerNorm                | 512   \n","136 | model.decoder.block.0.layer.2.dropout                               | Dropout                    | 0     \n","137 | model.decoder.block.1                                               | T5Block                    | 4 M   \n","138 | model.decoder.block.1.layer                                         | ModuleList                 | 4 M   \n","139 | model.decoder.block.1.layer.0                                       | T5LayerSelfAttention       | 1 M   \n","140 | model.decoder.block.1.layer.0.SelfAttention                         | T5Attention                | 1 M   \n","141 | model.decoder.block.1.layer.0.SelfAttention.q                       | Linear                     | 262 K \n","142 | model.decoder.block.1.layer.0.SelfAttention.k                       | Linear                     | 262 K \n","143 | model.decoder.block.1.layer.0.SelfAttention.v                       | Linear                     | 262 K \n","144 | model.decoder.block.1.layer.0.SelfAttention.o                       | Linear                     | 262 K \n","145 | model.decoder.block.1.layer.0.layer_norm                            | T5LayerNorm                | 512   \n","146 | model.decoder.block.1.layer.0.dropout                               | Dropout                    | 0     \n","147 | model.decoder.block.1.layer.1                                       | T5LayerCrossAttention      | 1 M   \n","148 | model.decoder.block.1.layer.1.EncDecAttention                       | T5Attention                | 1 M   \n","149 | model.decoder.block.1.layer.1.EncDecAttention.q                     | Linear                     | 262 K \n","150 | model.decoder.block.1.layer.1.EncDecAttention.k                     | Linear                     | 262 K \n","151 | model.decoder.block.1.layer.1.EncDecAttention.v                     | Linear                     | 262 K \n","152 | model.decoder.block.1.layer.1.EncDecAttention.o                     | Linear                     | 262 K \n","153 | model.decoder.block.1.layer.1.layer_norm                            | T5LayerNorm                | 512   \n","154 | model.decoder.block.1.layer.1.dropout                               | Dropout                    | 0     \n","155 | model.decoder.block.1.layer.2                                       | T5LayerFF                  | 2 M   \n","156 | model.decoder.block.1.layer.2.DenseReluDense                        | T5DenseReluDense           | 2 M   \n","157 | model.decoder.block.1.layer.2.DenseReluDense.wi                     | Linear                     | 1 M   \n","158 | model.decoder.block.1.layer.2.DenseReluDense.wo                     | Linear                     | 1 M   \n","159 | model.decoder.block.1.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","160 | model.decoder.block.1.layer.2.layer_norm                            | T5LayerNorm                | 512   \n","161 | model.decoder.block.1.layer.2.dropout                               | Dropout                    | 0     \n","162 | model.decoder.block.2                                               | T5Block                    | 4 M   \n","163 | model.decoder.block.2.layer                                         | ModuleList                 | 4 M   \n","164 | model.decoder.block.2.layer.0                                       | T5LayerSelfAttention       | 1 M   \n","165 | model.decoder.block.2.layer.0.SelfAttention                         | T5Attention                | 1 M   \n","166 | model.decoder.block.2.layer.0.SelfAttention.q                       | Linear                     | 262 K \n","167 | model.decoder.block.2.layer.0.SelfAttention.k                       | Linear                     | 262 K \n","168 | model.decoder.block.2.layer.0.SelfAttention.v                       | Linear                     | 262 K \n","169 | model.decoder.block.2.layer.0.SelfAttention.o                       | Linear                     | 262 K \n","170 | model.decoder.block.2.layer.0.layer_norm                            | T5LayerNorm                | 512   \n","171 | model.decoder.block.2.layer.0.dropout                               | Dropout                    | 0     \n","172 | model.decoder.block.2.layer.1                                       | T5LayerCrossAttention      | 1 M   \n","173 | model.decoder.block.2.layer.1.EncDecAttention                       | T5Attention                | 1 M   \n","174 | model.decoder.block.2.layer.1.EncDecAttention.q                     | Linear                     | 262 K \n","175 | model.decoder.block.2.layer.1.EncDecAttention.k                     | Linear                     | 262 K \n","176 | model.decoder.block.2.layer.1.EncDecAttention.v                     | Linear                     | 262 K \n","177 | model.decoder.block.2.layer.1.EncDecAttention.o                     | Linear                     | 262 K \n","178 | model.decoder.block.2.layer.1.layer_norm                            | T5LayerNorm                | 512   \n","179 | model.decoder.block.2.layer.1.dropout                               | Dropout                    | 0     \n","180 | model.decoder.block.2.layer.2                                       | T5LayerFF                  | 2 M   \n","181 | model.decoder.block.2.layer.2.DenseReluDense                        | T5DenseReluDense           | 2 M   \n","182 | model.decoder.block.2.layer.2.DenseReluDense.wi                     | Linear                     | 1 M   \n","183 | model.decoder.block.2.layer.2.DenseReluDense.wo                     | Linear                     | 1 M   \n","184 | model.decoder.block.2.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","185 | model.decoder.block.2.layer.2.layer_norm                            | T5LayerNorm                | 512   \n","186 | model.decoder.block.2.layer.2.dropout                               | Dropout                    | 0     \n","187 | model.decoder.block.3                                               | T5Block                    | 4 M   \n","188 | model.decoder.block.3.layer                                         | ModuleList                 | 4 M   \n","189 | model.decoder.block.3.layer.0                                       | T5LayerSelfAttention       | 1 M   \n","190 | model.decoder.block.3.layer.0.SelfAttention                         | T5Attention                | 1 M   \n","191 | model.decoder.block.3.layer.0.SelfAttention.q                       | Linear                     | 262 K \n","192 | model.decoder.block.3.layer.0.SelfAttention.k                       | Linear                     | 262 K \n","193 | model.decoder.block.3.layer.0.SelfAttention.v                       | Linear                     | 262 K \n","194 | model.decoder.block.3.layer.0.SelfAttention.o                       | Linear                     | 262 K \n","195 | model.decoder.block.3.layer.0.layer_norm                            | T5LayerNorm                | 512   \n","196 | model.decoder.block.3.layer.0.dropout                               | Dropout                    | 0     \n","197 | model.decoder.block.3.layer.1                                       | T5LayerCrossAttention      | 1 M   \n","198 | model.decoder.block.3.layer.1.EncDecAttention                       | T5Attention                | 1 M   \n","199 | model.decoder.block.3.layer.1.EncDecAttention.q                     | Linear                     | 262 K \n","200 | model.decoder.block.3.layer.1.EncDecAttention.k                     | Linear                     | 262 K \n","201 | model.decoder.block.3.layer.1.EncDecAttention.v                     | Linear                     | 262 K \n","202 | model.decoder.block.3.layer.1.EncDecAttention.o                     | Linear                     | 262 K \n","203 | model.decoder.block.3.layer.1.layer_norm                            | T5LayerNorm                | 512   \n","204 | model.decoder.block.3.layer.1.dropout                               | Dropout                    | 0     \n","205 | model.decoder.block.3.layer.2                                       | T5LayerFF                  | 2 M   \n","206 | model.decoder.block.3.layer.2.DenseReluDense                        | T5DenseReluDense           | 2 M   \n","207 | model.decoder.block.3.layer.2.DenseReluDense.wi                     | Linear                     | 1 M   \n","208 | model.decoder.block.3.layer.2.DenseReluDense.wo                     | Linear                     | 1 M   \n","209 | model.decoder.block.3.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","210 | model.decoder.block.3.layer.2.layer_norm                            | T5LayerNorm                | 512   \n","211 | model.decoder.block.3.layer.2.dropout                               | Dropout                    | 0     \n","212 | model.decoder.block.4                                               | T5Block                    | 4 M   \n","213 | model.decoder.block.4.layer                                         | ModuleList                 | 4 M   \n","214 | model.decoder.block.4.layer.0                                       | T5LayerSelfAttention       | 1 M   \n","215 | model.decoder.block.4.layer.0.SelfAttention                         | T5Attention                | 1 M   \n","216 | model.decoder.block.4.layer.0.SelfAttention.q                       | Linear                     | 262 K \n","217 | model.decoder.block.4.layer.0.SelfAttention.k                       | Linear                     | 262 K \n","218 | model.decoder.block.4.layer.0.SelfAttention.v                       | Linear                     | 262 K \n","219 | model.decoder.block.4.layer.0.SelfAttention.o                       | Linear                     | 262 K \n","220 | model.decoder.block.4.layer.0.layer_norm                            | T5LayerNorm                | 512   \n","221 | model.decoder.block.4.layer.0.dropout                               | Dropout                    | 0     \n","222 | model.decoder.block.4.layer.1                                       | T5LayerCrossAttention      | 1 M   \n","223 | model.decoder.block.4.layer.1.EncDecAttention                       | T5Attention                | 1 M   \n","224 | model.decoder.block.4.layer.1.EncDecAttention.q                     | Linear                     | 262 K \n","225 | model.decoder.block.4.layer.1.EncDecAttention.k                     | Linear                     | 262 K \n","226 | model.decoder.block.4.layer.1.EncDecAttention.v                     | Linear                     | 262 K \n","227 | model.decoder.block.4.layer.1.EncDecAttention.o                     | Linear                     | 262 K \n","228 | model.decoder.block.4.layer.1.layer_norm                            | T5LayerNorm                | 512   \n","229 | model.decoder.block.4.layer.1.dropout                               | Dropout                    | 0     \n","230 | model.decoder.block.4.layer.2                                       | T5LayerFF                  | 2 M   \n","231 | model.decoder.block.4.layer.2.DenseReluDense                        | T5DenseReluDense           | 2 M   \n","232 | model.decoder.block.4.layer.2.DenseReluDense.wi                     | Linear                     | 1 M   \n","233 | model.decoder.block.4.layer.2.DenseReluDense.wo                     | Linear                     | 1 M   \n","234 | model.decoder.block.4.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","235 | model.decoder.block.4.layer.2.layer_norm                            | T5LayerNorm                | 512   \n","236 | model.decoder.block.4.layer.2.dropout                               | Dropout                    | 0     \n","237 | model.decoder.block.5                                               | T5Block                    | 4 M   \n","238 | model.decoder.block.5.layer                                         | ModuleList                 | 4 M   \n","239 | model.decoder.block.5.layer.0                                       | T5LayerSelfAttention       | 1 M   \n","240 | model.decoder.block.5.layer.0.SelfAttention                         | T5Attention                | 1 M   \n","241 | model.decoder.block.5.layer.0.SelfAttention.q                       | Linear                     | 262 K \n","242 | model.decoder.block.5.layer.0.SelfAttention.k                       | Linear                     | 262 K \n","243 | model.decoder.block.5.layer.0.SelfAttention.v                       | Linear                     | 262 K \n","244 | model.decoder.block.5.layer.0.SelfAttention.o                       | Linear                     | 262 K \n","245 | model.decoder.block.5.layer.0.layer_norm                            | T5LayerNorm                | 512   \n","246 | model.decoder.block.5.layer.0.dropout                               | Dropout                    | 0     \n","247 | model.decoder.block.5.layer.1                                       | T5LayerCrossAttention      | 1 M   \n","248 | model.decoder.block.5.layer.1.EncDecAttention                       | T5Attention                | 1 M   \n","249 | model.decoder.block.5.layer.1.EncDecAttention.q                     | Linear                     | 262 K \n","250 | model.decoder.block.5.layer.1.EncDecAttention.k                     | Linear                     | 262 K \n","251 | model.decoder.block.5.layer.1.EncDecAttention.v                     | Linear                     | 262 K \n","252 | model.decoder.block.5.layer.1.EncDecAttention.o                     | Linear                     | 262 K \n","253 | model.decoder.block.5.layer.1.layer_norm                            | T5LayerNorm                | 512   \n","254 | model.decoder.block.5.layer.1.dropout                               | Dropout                    | 0     \n","255 | model.decoder.block.5.layer.2                                       | T5LayerFF                  | 2 M   \n","256 | model.decoder.block.5.layer.2.DenseReluDense                        | T5DenseReluDense           | 2 M   \n","257 | model.decoder.block.5.layer.2.DenseReluDense.wi                     | Linear                     | 1 M   \n","258 | model.decoder.block.5.layer.2.DenseReluDense.wo                     | Linear                     | 1 M   \n","259 | model.decoder.block.5.layer.2.DenseReluDense.dropout                | Dropout                    | 0     \n","260 | model.decoder.block.5.layer.2.layer_norm                            | T5LayerNorm                | 512   \n","261 | model.decoder.block.5.layer.2.dropout                               | Dropout                    | 0     \n","262 | model.decoder.final_layer_norm                                      | T5LayerNorm                | 512   \n","263 | model.decoder.dropout                                               | Dropout                    | 0     \n","264 | model.lm_head                                                       | Linear                     | 16 M  \n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f99502b27dda448aa5223f9333545789","version_minor":0,"version_major":2},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19b895793c6c4683bdfedb1914efc912","version_minor":0,"version_major":2},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0fd9a86ddb643bd8df34bf5b5621bbd","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Validation results *****\n","INFO:__main__:avg_val_loss = tensor(4.6165, device='cuda:0')\n","\n","INFO:__main__:loss = tensor(0.7044, device='cuda:0')\n","\n","INFO:__main__:train_loss = tensor(0.7044, device='cuda:0')\n","\n","INFO:__main__:val_loss = tensor(4.6165, device='cuda:0')\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6882fafe84284c16b978d8503beb598b","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Validation results *****\n","INFO:__main__:avg_train_loss = tensor(2.1427, device='cuda:0')\n","\n","INFO:__main__:avg_val_loss = tensor(4.6375, device='cuda:0')\n","\n","INFO:__main__:epoch = 6\n","\n","INFO:__main__:loss = tensor(2.0052, device='cuda:0')\n","\n","INFO:__main__:train_loss = tensor(2.0052, device='cuda:0')\n","\n","INFO:__main__:val_loss = tensor(4.6375, device='cuda:0')\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1d9829b85134135bac7c92837847036","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Validation results *****\n","INFO:__main__:avg_train_loss = tensor(2.0546, device='cuda:0')\n","\n","INFO:__main__:avg_val_loss = tensor(4.6009, device='cuda:0')\n","\n","INFO:__main__:epoch = 7\n","\n","INFO:__main__:loss = tensor(1.3006, device='cuda:0')\n","\n","INFO:__main__:train_loss = tensor(1.3006, device='cuda:0')\n","\n","INFO:__main__:val_loss = tensor(4.6009, device='cuda:0')\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c62d16743014791ac85e8e87b2814c2","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:***** Validation results *****\n","INFO:__main__:avg_train_loss = tensor(1.9889, device='cuda:0')\n","\n","INFO:__main__:avg_val_loss = tensor(4.6435, device='cuda:0')\n","\n","INFO:__main__:epoch = 8\n","\n","INFO:__main__:loss = tensor(2.3612, device='cuda:0')\n","\n","INFO:__main__:train_loss = tensor(2.3612, device='cuda:0')\n","\n","INFO:__main__:val_loss = tensor(4.6435, device='cuda:0')\n","\n"]},{"output_type":"stream","name":"stdout","text":["training finished\n","Saving model\n","Model saved\n","Copied the final folder to Google Drive\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"0tShhMdo6BxM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing"],"metadata":{"id":"2RC4vH2aYgZh"}},{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOk95AWhYoLJ","executionInfo":{"status":"ok","timestamp":1639559907246,"user_tz":-420,"elapsed":9964,"user":{"displayName":"Quang Vu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11086209231479786423"}},"outputId":"d0d85ed7-b103-45f3-ab5b-9eb37eb7a62e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 13.7 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 32.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 528 kB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 42.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 39.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.13.0\n"]}]},{"cell_type":"code","source":["pip install sentencepiece "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQ172Ay-aMyy","executionInfo":{"status":"ok","timestamp":1639560401054,"user_tz":-420,"elapsed":6513,"user":{"displayName":"Quang Vu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11086209231479786423"}},"outputId":"29105d2e-f2ac-4dca-dbe7-43be57182c3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"6fSE0Owlc8g-"}}]}